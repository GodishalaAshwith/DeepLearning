{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOedzfPT9B3SBFqA2/d44gY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GodishalaAshwith/DeepLearning/blob/main/DL_Lab_Exp_25_26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 1"
      ],
      "metadata": {
        "id": "l6V9TuWd_u61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Vs Tensorflow Vs Keras"
      ],
      "metadata": {
        "id": "E5Q1N1iXCWBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "x = torch.rand(100, 3)\n",
        "y = torch.rand(100, 1)\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = SimpleNet()\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "s = {}\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    loss_value = round(loss.item(), 6)\n",
        "\n",
        "    if loss_value not in s:\n",
        "        s[loss_value] = 1\n",
        "    else:\n",
        "        s[loss_value] += 1\n",
        "        if s[loss_value] > 5:\n",
        "            print(f\"Stopping early at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Final loss:\", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ZzYwv-599T",
        "outputId": "fa118596-a53d-4dea-d8b2-01ecfbf810d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 0.0919896587729454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Code: Simple Neural Network with TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.random.normal((100, 3))\n",
        "y = tf.random.normal((100, 1))\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(3,))])\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "\n",
        "model.fit(x, y,epochs=100,verbose=0)\n",
        "\n",
        "print(\"Final loss:\",model.evaluate(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDCCUWF_Bgwj",
        "outputId": "64421115-d52e-4107-a3c1-329373596b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8820 \n",
            "Final loss: 0.9106503129005432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Code: Same Network Using Keras (via tf.keras)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "x = tf.random.normal((100, 3))\n",
        "y = tf.random.normal((100, 1))\n",
        "\n",
        "\n",
        "model = keras.Sequential([layers.Dense(1, input_shape=(3,)) ])\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "\n",
        "model.fit(x, y,epochs=100,verbose=0)\n",
        "\n",
        "print(\"Final loss:\",model.evaluate(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcQHz5OzB-CL",
        "outputId": "58cf1634-0297-490d-e036-bce1accb2020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5867\n",
            "Final loss: 1.5753376483917236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Perceptron"
      ],
      "metadata": {
        "id": "XF2ZCAvuCbOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPLEMENT A SIMPLE PERCEPTRON (Coding a Neuron)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1])\n",
        "bias = 4\n",
        "\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])\n",
        "print(n.feedforward(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUPJXE2ZCfER",
        "outputId": "933e0199-2a9c-401c-f239-9009cb7726b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prg 1 - 3 Logic Gates"
      ],
      "metadata": {
        "id": "LBhfBpPjC5CR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 1 And Gate, OR Gate"
      ],
      "metadata": {
        "id": "ozWxk_jhDG4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def predict(self,input):\n",
        "    total = np.dot(self.weights,input) + self.bias\n",
        "    return step(total)\n",
        "\n",
        "weights = np.array([1,1])\n",
        "bias = -1.5\n",
        "\n",
        "and_gate = Perceptron(weights,bias)\n",
        "\n",
        "print(\"And Gate\")\n",
        "for x in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "  print(x, '->' , and_gate.predict(np.array(x)))\n",
        "\n",
        "\n",
        "weights = np.array([1, 1])\n",
        "bias = -0.5\n",
        "\n",
        "or_gate = Perceptron(weights, bias)\n",
        "\n",
        "print(\"OR Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", or_gate.predict(np.array(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFMlXwqVDDvF",
        "outputId": "32cc33e4-193a-4d70-efce-36832bf2ae91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 0\n",
            "(1, 0) -> 0\n",
            "(1, 1) -> 1\n",
            "OR Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Not Gate"
      ],
      "metadata": {
        "id": "eN1eis9vF69-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "weights = np.array([-1])\n",
        "bias = 0.5\n",
        "\n",
        "not_gate = Perceptron(weights, bias)\n",
        "\n",
        "print(\"NOT Gate\")\n",
        "for x in [0, 1]:\n",
        "    print(x, \"->\", not_gate.predict(np.array([x])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3OANgF1F9HH",
        "outputId": "d31ae8ca-a4be-44e2-e387-f5b710329b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT Gate\n",
            "0 -> 1\n",
            "1 -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 2. XOR & XNOR using single perceptron\n"
      ],
      "metadata": {
        "id": "KmO8KaLw31Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = np.array(weights)\n",
        "        self.bias = bias\n",
        "\n",
        "    def predict(self, x):\n",
        "        return step(np.dot(self.weights, x) + self.bias)\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "Y_xor = np.array([0,1,1,0])\n",
        "\n",
        "p = Perceptron(weights=[1, 1], bias=-1)\n",
        "\n",
        "print(\"XOR Predictions:\")\n",
        "for x, y in zip(X, Y_xor):\n",
        "    print(x, \"Predicted:\", p.predict(x), \"Actual:\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP93wV_b36uK",
        "outputId": "08913f7b-3526-4d9b-86e8-c80f64e15472"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Predictions:\n",
            "[0 0] Predicted: 0 Actual: 0\n",
            "[0 1] Predicted: 1 Actual: 1\n",
            "[1 0] Predicted: 1 Actual: 1\n",
            "[1 1] Predicted: 1 Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 3. XOR Gate, XNOR Gate"
      ],
      "metadata": {
        "id": "mIQ4jyTtEeJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "class XoR:\n",
        "  def __init__(self):\n",
        "    self.w_or = self.w_and = np.array([1,1])\n",
        "    self.b_or = -0.5; self.b_and = -1.5\n",
        "\n",
        "    self.w_out = np.array([1,-2])\n",
        "    self.b_out = -0.5\n",
        "\n",
        "  def predict(self,x):\n",
        "    h1 = step(np.dot(self.w_or,x)+self.b_or)\n",
        "    h2 = step(np.dot(self.w_and,x)+self.b_and)\n",
        "\n",
        "    output = step(self.w_out[0]*h1 + self.w_out[1]*h2 + self.b_out)\n",
        "    return output\n",
        "\n",
        "xor = XoR()\n",
        "print(\"XOR Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", xor.predict(np.array(x)))\n",
        "\n",
        "#XNOR\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "class XNoR:\n",
        "  def __init__(self):\n",
        "    self.w_or = self.w_and = np.array([1,1])\n",
        "    self.b_or = -0.5; self.b_and = -1.5\n",
        "\n",
        "    self.w_out = np.array([1,-2])\n",
        "    self.b_out = -0.5\n",
        "\n",
        "  def predict(self,x):\n",
        "    h1 = step(np.dot(self.w_or,x)+self.b_or)\n",
        "    h2 = step(np.dot(self.w_and,x)+self.b_and)\n",
        "\n",
        "    and_out = step(self.w_out[0]*h1 + self.w_out[1]*h2 + self.b_out)\n",
        "    output = step(and_out*-1 + 0.5)\n",
        "    return output\n",
        "\n",
        "xor = XNoR()\n",
        "print(\"XNOR Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", xor.predict(np.array(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Qsz2qyEdkK",
        "outputId": "9078884f-e5d9-4074-f578-e1f8a71f60c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 0\n",
            "XNOR Gate\n",
            "(0, 0) -> 1\n",
            "(0, 1) -> 0\n",
            "(1, 0) -> 0\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 4."
      ],
      "metadata": {
        "id": "iJnALOEU4ddy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "print(step(1))\n",
        "print(step(0.00000001))\n",
        "print(step(-0.00000001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ7ebe1z4juh",
        "outputId": "d5a7b0ef-f6b6-4071-fd32-c3e67a20a84a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 5"
      ],
      "metadata": {
        "id": "mclIt3UX44X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'f1': [1, 1, 0, 0, 0, 1, 0, 1],\n",
        "    'f2': [1, 0, 1, 0, 0, 0, 1, 1],\n",
        "    'f3': [0, 0, 1, 1, 0, 1, 0, 1],\n",
        "    'f4': [0.85, 0.60, 0.90, 0.75, 0.40, 0.30, 0.45, 0.95],\n",
        "    'y' : [1, 1, 1, 1, 0, 0, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['f1', 'f2', 'f3', 'f4']].values\n",
        "y = df['y'].values\n",
        "\n",
        "def step(z,threshold=0):\n",
        "    return 1 if z >= threshold else 0\n",
        "\n",
        "# i) MP Perceptron (No weights, No bias)\n",
        "print(\"MP PERCEPTRON (No weights, No bias)\")\n",
        "\n",
        "def mp_perceptron(x,threshold=0):\n",
        "    return step(np.sum(x),threshold)\n",
        "\n",
        "for i in range(len(X)):\n",
        "    pred = mp_perceptron(X[i],1)\n",
        "    print(f\"Input: {X[i]}  True: {y[i]}  Predicted: {pred}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwpliXkW45QR",
        "outputId": "5ce4419e-5a07-4084-bea8-590ec72983e9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP PERCEPTRON (No weights, No bias)\n",
            "Input: [1.   1.   0.   0.85]  True: 1  Predicted: 1\n",
            "Input: [1.  0.  0.  0.6]  True: 1  Predicted: 1\n",
            "Input: [0.  1.  1.  0.9]  True: 1  Predicted: 1\n",
            "Input: [0.   0.   1.   0.75]  True: 1  Predicted: 1\n",
            "Input: [0.  0.  0.  0.4]  True: 0  Predicted: 0\n",
            "Input: [1.  0.  1.  0.3]  True: 0  Predicted: 1\n",
            "Input: [0.   1.   0.   0.45]  True: 0  Predicted: 1\n",
            "Input: [1.   1.   1.   0.95]  True: 1  Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ii) Perceptron with Weights ONLY\n",
        "print(\"\\nPERCEPTRON WITH WEIGHTS ONLY\")\n",
        "\n",
        "def train_perceptron_weights_only(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            z = np.dot(w, X[i])\n",
        "            y_pred = step(z)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            errors += abs(error)\n",
        "        print(f\"Epoch {epoch+1} | Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w\n",
        "\n",
        "w_no_bias = train_perceptron_weights_only(X, y)\n",
        "print(\"Final Weights (No Bias):\", w_no_bias)\n",
        "\n",
        "# iii) Perceptron with Weights AND Bias\n",
        "print(\"\\nPERCEPTRON WITH WEIGHTS AND BIAS\")\n",
        "\n",
        "def train_perceptron(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            z = np.dot(w, X[i]) + b\n",
        "            y_pred = step(z)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            b += lr * error\n",
        "            errors += abs(error)\n",
        "        print(f\"Epoch {epoch+1} | Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w, b\n",
        "\n",
        "w, b = train_perceptron(X, y)\n",
        "print(\"Final Weights:\", w)\n",
        "print(\"Final Bias:\", b)\n",
        "\n",
        "# iv) Testing with a Sample Movie\n",
        "print(\"\\nTESTING WITH A SAMPLE MOVIE\")\n",
        "\n",
        "test_movie = np.array([1, 1, 0, 0.80])\n",
        "\n",
        "mp_result = mp_perceptron(test_movie)\n",
        "no_bias_result = step(np.dot(w_no_bias, test_movie))\n",
        "bias_result = step(np.dot(w, test_movie) + b)\n",
        "\n",
        "print(\"Test Movie Features:\", test_movie)\n",
        "print(\"MP Perceptron Prediction:\", mp_result)\n",
        "print(\"Perceptron (Weights Only) Prediction:\", no_bias_result)\n",
        "print(\"Perceptron (Weights + Bias) Prediction:\", bias_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pccd5dhOBpTg",
        "outputId": "0b07c5f4-0d8f-4502-e52e-0b77fb65d6da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PERCEPTRON WITH WEIGHTS ONLY\n",
            "Epoch 1 | Errors: 2\n",
            "Epoch 2 | Errors: 4\n",
            "Epoch 3 | Errors: 4\n",
            "Epoch 4 | Errors: 4\n",
            "Epoch 5 | Errors: 3\n",
            "Epoch 6 | Errors: 4\n",
            "Epoch 7 | Errors: 3\n",
            "Epoch 8 | Errors: 4\n",
            "Epoch 9 | Errors: 3\n",
            "Epoch 10 | Errors: 4\n",
            "Epoch 11 | Errors: 3\n",
            "Epoch 12 | Errors: 4\n",
            "Epoch 13 | Errors: 3\n",
            "Epoch 14 | Errors: 4\n",
            "Epoch 15 | Errors: 3\n",
            "Epoch 16 | Errors: 4\n",
            "Epoch 17 | Errors: 3\n",
            "Epoch 18 | Errors: 4\n",
            "Epoch 19 | Errors: 3\n",
            "Epoch 20 | Errors: 4\n",
            "Final Weights (No Bias): [ 0.1    0.1    0.1   -0.005]\n",
            "\n",
            "PERCEPTRON WITH WEIGHTS AND BIAS\n",
            "Epoch 1 | Errors: 2\n",
            "Epoch 2 | Errors: 3\n",
            "Epoch 3 | Errors: 3\n",
            "Epoch 4 | Errors: 4\n",
            "Epoch 5 | Errors: 1\n",
            "Epoch 6 | Errors: 4\n",
            "Epoch 7 | Errors: 4\n",
            "Epoch 8 | Errors: 3\n",
            "Epoch 9 | Errors: 3\n",
            "Epoch 10 | Errors: 0\n",
            "Final Weights: [0.1 0.1 0.  0.4]\n",
            "Final Bias: -0.30000000000000004\n",
            "\n",
            "TESTING WITH A SAMPLE MOVIE\n",
            "Test Movie Features: [1.  1.  0.  0.8]\n",
            "MP Perceptron Prediction: 1\n",
            "Perceptron (Weights Only) Prediction: 1\n",
            "Perceptron (Weights + Bias) Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset\n",
        "# f1: Matt Damon\n",
        "# f2: Thriller\n",
        "# f3: Christopher Nolan\n",
        "# f4: IMDb rating (0–1)\n",
        "# y : Like(1) / Dislike(0)\n",
        "X = np.array([\n",
        "    [1, 1, 0, 0.85],\n",
        "    [1, 0, 0, 0.60],\n",
        "    [0, 1, 1, 0.90],\n",
        "    [0, 0, 1, 0.75],\n",
        "    [0, 0, 0, 0.40],\n",
        "    [1, 0, 1, 0.30],\n",
        "    [0, 1, 0, 0.45],\n",
        "    [1, 1, 1, 0.95]\n",
        "])\n",
        "\n",
        "y = np.array([1, 1, 1, 1, 0, 0, 0, 1])\n",
        "\n",
        "def step(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "\n",
        "# i) MP Perceptron (No weights, No bias)\n",
        "def mp_perceptron(x):\n",
        "    return step(np.sum(x))\n",
        "\n",
        "# ii) Perceptron with Weights ONLY\n",
        "def train_weights_only(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    for _ in range(epochs):\n",
        "        for i in range(len(X)):\n",
        "            error = y[i] - step(np.dot(w, X[i]))\n",
        "            w += lr * error * X[i]\n",
        "    return w\n",
        "\n",
        "# iii) Perceptron with Weights AND Bias\n",
        "def train_weights_bias(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "    for _ in range(epochs):\n",
        "        for i in range(len(X)):\n",
        "            error = y[i] - step(np.dot(w, X[i]) + b)\n",
        "            w += lr * error * X[i]\n",
        "            b += lr * error\n",
        "    return w, b\n",
        "\n",
        "# Training\n",
        "w_only = train_weights_only(X, y)\n",
        "w, b = train_weights_bias(X, y)\n",
        "\n",
        "# Testing with a sample movie\n",
        "test_movie = np.array([1, 1, 0, 0.80])\n",
        "\n",
        "print(\"MP Perceptron:\", mp_perceptron(test_movie))\n",
        "print(\"Weights Only:\", step(np.dot(w_only, test_movie)))\n",
        "print(\"Weights + Bias:\", step(np.dot(w, test_movie) + b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGUCmM2ADuLu",
        "outputId": "1ff55476-2a6e-47db-bd54-95455a1093ad"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP Perceptron: 1\n",
            "Weights Only: 1\n",
            "Weights + Bias: 1\n"
          ]
        }
      ]
    }
  ]
}