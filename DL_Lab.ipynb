{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l6V9TuWd_u61",
        "-FUXAEan-CIz",
        "8C4o7XBK3jKz"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRm3x7GRMZLJj7EWGFovL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GodishalaAshwith/DeepLearning/blob/main/DL_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 1"
      ],
      "metadata": {
        "id": "l6V9TuWd_u61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Vs Tensorflow Vs Keras"
      ],
      "metadata": {
        "id": "E5Q1N1iXCWBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "x = torch.rand(100, 3)\n",
        "y = torch.rand(100, 1)\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = SimpleNet()\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "s = {}\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    loss_value = round(loss.item(), 6)\n",
        "\n",
        "    if loss_value not in s:\n",
        "        s[loss_value] = 1\n",
        "    else:\n",
        "        s[loss_value] += 1\n",
        "        if s[loss_value] > 5:\n",
        "            print(f\"Stopping early at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Final loss:\", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ZzYwv-599T",
        "outputId": "fa118596-a53d-4dea-d8b2-01ecfbf810d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 0.0919896587729454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Code: Simple Neural Network with TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.random.normal((100, 3))\n",
        "y = tf.random.normal((100, 1))\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(3,))])\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "\n",
        "model.fit(x, y,epochs=100,verbose=0)\n",
        "\n",
        "print(\"Final loss:\",model.evaluate(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDCCUWF_Bgwj",
        "outputId": "64421115-d52e-4107-a3c1-329373596b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8820 \n",
            "Final loss: 0.9106503129005432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Code: Same Network Using Keras (via tf.keras)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "x = tf.random.normal((100, 3))\n",
        "y = tf.random.normal((100, 1))\n",
        "\n",
        "\n",
        "model = keras.Sequential([layers.Dense(1, input_shape=(3,)) ])\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "\n",
        "model.fit(x, y,epochs=100,verbose=0)\n",
        "\n",
        "print(\"Final loss:\",model.evaluate(x, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcQHz5OzB-CL",
        "outputId": "58cf1634-0297-490d-e036-bce1accb2020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5867\n",
            "Final loss: 1.5753376483917236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Perceptron"
      ],
      "metadata": {
        "id": "XF2ZCAvuCbOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPLEMENT A SIMPLE PERCEPTRON (Coding a Neuron)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1])\n",
        "bias = 4\n",
        "\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])\n",
        "print(n.feedforward(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUPJXE2ZCfER",
        "outputId": "933e0199-2a9c-401c-f239-9009cb7726b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week - 2\n"
      ],
      "metadata": {
        "id": "-FUXAEan-CIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prg 1 - 3 Logic Gates"
      ],
      "metadata": {
        "id": "LBhfBpPjC5CR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 1 And Gate, OR Gate"
      ],
      "metadata": {
        "id": "ozWxk_jhDG4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self,weights,bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def predict(self,input):\n",
        "    total = np.dot(self.weights,input) + self.bias\n",
        "    return step(total)\n",
        "\n",
        "weights = np.array([1,1])\n",
        "bias = -1.5\n",
        "\n",
        "and_gate = Perceptron(weights,bias)\n",
        "\n",
        "print(\"And Gate\")\n",
        "for x in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "  print(x, '->' , and_gate.predict(np.array(x)))\n",
        "\n",
        "\n",
        "weights = np.array([1, 1])\n",
        "bias = -0.5\n",
        "\n",
        "or_gate = Perceptron(weights, bias)\n",
        "\n",
        "print(\"OR Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", or_gate.predict(np.array(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFMlXwqVDDvF",
        "outputId": "32cc33e4-193a-4d70-efce-36832bf2ae91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 0\n",
            "(1, 0) -> 0\n",
            "(1, 1) -> 1\n",
            "OR Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Not Gate"
      ],
      "metadata": {
        "id": "eN1eis9vF69-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "weights = np.array([-1])\n",
        "bias = 0.5\n",
        "\n",
        "not_gate = Perceptron(weights, bias)\n",
        "\n",
        "print(\"NOT Gate\")\n",
        "for x in [0, 1]:\n",
        "    print(x, \"->\", not_gate.predict(np.array([x])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3OANgF1F9HH",
        "outputId": "d31ae8ca-a4be-44e2-e387-f5b710329b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT Gate\n",
            "0 -> 1\n",
            "1 -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 2. XOR & XNOR using single perceptron\n"
      ],
      "metadata": {
        "id": "KmO8KaLw31Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = np.array(weights)\n",
        "        self.bias = bias\n",
        "\n",
        "    def predict(self, x):\n",
        "        return step(np.dot(self.weights, x) + self.bias)\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "Y_xor = np.array([0,1,1,0])\n",
        "\n",
        "p = Perceptron(weights=[1, 1], bias=-1)\n",
        "\n",
        "print(\"XOR Predictions:\")\n",
        "for x, y in zip(X, Y_xor):\n",
        "    print(x, \"Predicted:\", p.predict(x), \"Actual:\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP93wV_b36uK",
        "outputId": "08913f7b-3526-4d9b-86e8-c80f64e15472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Predictions:\n",
            "[0 0] Predicted: 0 Actual: 0\n",
            "[0 1] Predicted: 1 Actual: 1\n",
            "[1 0] Predicted: 1 Actual: 1\n",
            "[1 1] Predicted: 1 Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 3. XOR Gate, XNOR Gate"
      ],
      "metadata": {
        "id": "mIQ4jyTtEeJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "class XoR:\n",
        "  def __init__(self):\n",
        "    self.w_or = self.w_and = np.array([1,1])\n",
        "    self.b_or = -0.5; self.b_and = -1.5\n",
        "\n",
        "    self.w_out = np.array([1,-2])\n",
        "    self.b_out = -0.5\n",
        "\n",
        "  def predict(self,x):\n",
        "    h1 = step(np.dot(self.w_or,x)+self.b_or)\n",
        "    h2 = step(np.dot(self.w_and,x)+self.b_and)\n",
        "\n",
        "    output = step(self.w_out[0]*h1 + self.w_out[1]*h2 + self.b_out)\n",
        "    return output\n",
        "\n",
        "xor = XoR()\n",
        "print(\"XOR Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", xor.predict(np.array(x)))\n",
        "\n",
        "#XNOR\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "class XNoR:\n",
        "  def __init__(self):\n",
        "    self.w_or = self.w_and = np.array([1,1])\n",
        "    self.b_or = -0.5; self.b_and = -1.5\n",
        "\n",
        "    self.w_out = np.array([1,-2])\n",
        "    self.b_out = -0.5\n",
        "\n",
        "  def predict(self,x):\n",
        "    h1 = step(np.dot(self.w_or,x)+self.b_or)\n",
        "    h2 = step(np.dot(self.w_and,x)+self.b_and)\n",
        "\n",
        "    and_out = step(self.w_out[0]*h1 + self.w_out[1]*h2 + self.b_out)\n",
        "    output = step(and_out*-1 + 0.5)\n",
        "    return output\n",
        "\n",
        "xor = XNoR()\n",
        "print(\"XNOR Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", xor.predict(np.array(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Qsz2qyEdkK",
        "outputId": "9078884f-e5d9-4074-f578-e1f8a71f60c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 0\n",
            "XNOR Gate\n",
            "(0, 0) -> 1\n",
            "(0, 1) -> 0\n",
            "(1, 0) -> 0\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 4."
      ],
      "metadata": {
        "id": "iJnALOEU4ddy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "\n",
        "print(step(1))\n",
        "print(step(0.00000001))\n",
        "print(step(-0.00000001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ7ebe1z4juh",
        "outputId": "d5a7b0ef-f6b6-4071-fd32-c3e67a20a84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 5"
      ],
      "metadata": {
        "id": "mclIt3UX44X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'f1': [1, 1, 0, 0, 0, 1, 0, 1],\n",
        "    'f2': [1, 0, 1, 0, 0, 0, 1, 1],\n",
        "    'f3': [0, 0, 1, 1, 0, 1, 0, 1],\n",
        "    'f4': [0.85, 0.60, 0.90, 0.75, 0.40, 0.30, 0.45, 0.95],\n",
        "    'y' : [1, 1, 1, 1, 0, 0, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['f1', 'f2', 'f3', 'f4']].values\n",
        "y = df['y'].values\n",
        "\n",
        "def step(z,threshold=0):\n",
        "    return 1 if z >= threshold else 0\n",
        "\n",
        "# i) MP Perceptron (No weights, No bias)\n",
        "print(\"MP PERCEPTRON (No weights, No bias)\")\n",
        "\n",
        "def mp_perceptron(x,threshold=0):\n",
        "    return step(np.sum(x),threshold)\n",
        "\n",
        "for i in range(len(X)):\n",
        "    pred = mp_perceptron(X[i],1)\n",
        "    print(f\"Input: {X[i]}  True: {y[i]}  Predicted: {pred}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwpliXkW45QR",
        "outputId": "5ce4419e-5a07-4084-bea8-590ec72983e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MP PERCEPTRON (No weights, No bias)\n",
            "Input: [1.   1.   0.   0.85]  True: 1  Predicted: 1\n",
            "Input: [1.  0.  0.  0.6]  True: 1  Predicted: 1\n",
            "Input: [0.  1.  1.  0.9]  True: 1  Predicted: 1\n",
            "Input: [0.   0.   1.   0.75]  True: 1  Predicted: 1\n",
            "Input: [0.  0.  0.  0.4]  True: 0  Predicted: 0\n",
            "Input: [1.  0.  1.  0.3]  True: 0  Predicted: 1\n",
            "Input: [0.   1.   0.   0.45]  True: 0  Predicted: 1\n",
            "Input: [1.   1.   1.   0.95]  True: 1  Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ii) Perceptron with Weights ONLY\n",
        "print(\"\\nPERCEPTRON WITH WEIGHTS ONLY\")\n",
        "\n",
        "def train_perceptron_weights_only(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            z = np.dot(w, X[i])\n",
        "            y_pred = step(z)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            errors += abs(error)\n",
        "        print(f\"Epoch {epoch+1} | Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w\n",
        "\n",
        "w_no_bias = train_perceptron_weights_only(X, y)\n",
        "print(\"Final Weights (No Bias):\", w_no_bias)\n",
        "\n",
        "# iii) Perceptron with Weights AND Bias\n",
        "print(\"\\nPERCEPTRON WITH WEIGHTS AND BIAS\")\n",
        "\n",
        "def train_perceptron(X, y, lr=0.1, epochs=20):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            z = np.dot(w, X[i]) + b\n",
        "            y_pred = step(z)\n",
        "            error = y[i] - y_pred\n",
        "            w += lr * error * X[i]\n",
        "            b += lr * error\n",
        "            errors += abs(error)\n",
        "        print(f\"Epoch {epoch+1} | Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w, b\n",
        "\n",
        "w, b = train_perceptron(X, y)\n",
        "print(\"Final Weights:\", w)\n",
        "print(\"Final Bias:\", b)\n",
        "\n",
        "# iv) Testing with a Sample Movie\n",
        "print(\"\\nTESTING WITH A SAMPLE MOVIE\")\n",
        "\n",
        "test_movie = np.array([1, 1, 0, 0.80])\n",
        "\n",
        "mp_result = mp_perceptron(test_movie)\n",
        "no_bias_result = step(np.dot(w_no_bias, test_movie))\n",
        "bias_result = step(np.dot(w, test_movie) + b)\n",
        "\n",
        "print(\"Test Movie Features:\", test_movie)\n",
        "print(\"MP Perceptron Prediction:\", mp_result)\n",
        "print(\"Perceptron (Weights Only) Prediction:\", no_bias_result)\n",
        "print(\"Perceptron (Weights + Bias) Prediction:\", bias_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pccd5dhOBpTg",
        "outputId": "0b07c5f4-0d8f-4502-e52e-0b77fb65d6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PERCEPTRON WITH WEIGHTS ONLY\n",
            "Epoch 1 | Errors: 2\n",
            "Epoch 2 | Errors: 4\n",
            "Epoch 3 | Errors: 4\n",
            "Epoch 4 | Errors: 4\n",
            "Epoch 5 | Errors: 3\n",
            "Epoch 6 | Errors: 4\n",
            "Epoch 7 | Errors: 3\n",
            "Epoch 8 | Errors: 4\n",
            "Epoch 9 | Errors: 3\n",
            "Epoch 10 | Errors: 4\n",
            "Epoch 11 | Errors: 3\n",
            "Epoch 12 | Errors: 4\n",
            "Epoch 13 | Errors: 3\n",
            "Epoch 14 | Errors: 4\n",
            "Epoch 15 | Errors: 3\n",
            "Epoch 16 | Errors: 4\n",
            "Epoch 17 | Errors: 3\n",
            "Epoch 18 | Errors: 4\n",
            "Epoch 19 | Errors: 3\n",
            "Epoch 20 | Errors: 4\n",
            "Final Weights (No Bias): [ 0.1    0.1    0.1   -0.005]\n",
            "\n",
            "PERCEPTRON WITH WEIGHTS AND BIAS\n",
            "Epoch 1 | Errors: 2\n",
            "Epoch 2 | Errors: 3\n",
            "Epoch 3 | Errors: 3\n",
            "Epoch 4 | Errors: 4\n",
            "Epoch 5 | Errors: 1\n",
            "Epoch 6 | Errors: 4\n",
            "Epoch 7 | Errors: 4\n",
            "Epoch 8 | Errors: 3\n",
            "Epoch 9 | Errors: 3\n",
            "Epoch 10 | Errors: 0\n",
            "Final Weights: [0.1 0.1 0.  0.4]\n",
            "Final Bias: -0.30000000000000004\n",
            "\n",
            "TESTING WITH A SAMPLE MOVIE\n",
            "Test Movie Features: [1.  1.  0.  0.8]\n",
            "MP Perceptron Prediction: 1\n",
            "Perceptron (Weights Only) Prediction: 1\n",
            "Perceptron (Weights + Bias) Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 6"
      ],
      "metadata": {
        "id": "-wfebNJ9-Vid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Demonstration of Representation Power of a Perceptron Network\n",
        "Covers:\n",
        "(a) Number of Boolean functions for two inputs\n",
        "(b) Linear separability check\n",
        "(c) Single perceptron learning test\n",
        "(d) Growth analysis of non-linearly separable Boolean functions\n",
        "\"\"\"\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "# (a) Number of Boolean functions\n",
        "def number_of_boolean_functions(n):\n",
        "    return 2 ** (2 ** n)\n",
        "\n",
        "print(\"Number of Boolean functions for 2 inputs:\",\n",
        "      number_of_boolean_functions(2))\n",
        "\n",
        "\n",
        "# Generate all Boolean functions for n binary inputs\n",
        "def generate_boolean_functions(n):\n",
        "    inputs = list(itertools.product([0, 1], repeat=n))\n",
        "    outputs = list(itertools.product([0, 1], repeat=len(inputs)))\n",
        "    return inputs, outputs\n",
        "\n",
        "\n",
        "# Perceptron implementation\n",
        "class Perceptron:\n",
        "    def __init__(self, lr=0.1, epochs=100):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.w = np.zeros(X.shape[1])\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            error = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                y_pred = self.predict(xi)\n",
        "                update = self.lr * (target - y_pred)\n",
        "                self.w += update * xi\n",
        "                self.b += update\n",
        "                error += abs(target - y_pred)\n",
        "            if error == 0:\n",
        "                return True   # linearly separable\n",
        "        return False          # not linearly separable\n",
        "\n",
        "    def predict(self, x):\n",
        "        return 1 if np.dot(x, self.w) + self.b >= 0 else 0\n",
        "\n",
        "\n",
        "# (b) Check linear separability for each Boolean fn\n",
        "def check_linear_separability(n):\n",
        "    inputs, functions = generate_boolean_functions(n)\n",
        "    X = np.array(inputs)\n",
        "\n",
        "    separable = []\n",
        "    non_separable = []\n",
        "\n",
        "    for idx, f in enumerate(functions, 1):\n",
        "        p = Perceptron()\n",
        "        success = p.fit(X, np.array(f))\n",
        "        if success:\n",
        "            separable.append(idx)\n",
        "        else:\n",
        "            non_separable.append(idx)\n",
        "\n",
        "    return separable, non_separable\n",
        "\n",
        "\n",
        "sep, non_sep = check_linear_separability(2)\n",
        "\n",
        "print(\"\\nLinearly separable Boolean functions (2 inputs):\", sep)\n",
        "print(\"Non-linearly separable Boolean functions (2 inputs):\", non_sep)\n",
        "print(\"Count:\")\n",
        "print(\"  Separable:\", len(sep))\n",
        "print(\"  Non-separable:\", len(non_sep))\n",
        "\n",
        "\n",
        "# (c) Explicit perceptron learning test for all functions\n",
        "print(\"\\nPerceptron learning results:\")\n",
        "for i in range(1, 17):\n",
        "    status = \"Learned\" if i in sep else \"Not Learned\"\n",
        "    print(f\"Function f{i}: {status}\")\n",
        "\n",
        "print(\"\\nReason perceptron fails:\")\n",
        "print(\"A single perceptron cannot learn non-linearly separable functions\")\n",
        "print(\"such as XOR and XNOR due to absence of a linear decision boundary.\")\n",
        "\n",
        "\n",
        "# (d) Growth of non-linearly separable functions vs n\n",
        "def analyze_growth(max_n=4):\n",
        "    print(\"\\nGrowth of Non-Linearly Separable Boolean Functions:\")\n",
        "    print(\"n | Total Functions | Linearly Separable | Non-Linearly Separable\")\n",
        "    print(\"-\" * 65)\n",
        "\n",
        "    for n in range(1, max_n + 1):\n",
        "        total = number_of_boolean_functions(n)\n",
        "        if n <= 3:\n",
        "            sep, non_sep = check_linear_separability(n)\n",
        "            linear = len(sep)\n",
        "            non_linear = len(non_sep)\n",
        "        else:\n",
        "            # Known results / estimates for higher n\n",
        "            linear = \"Very Small\"\n",
        "            non_linear = \"Almost All\"\n",
        "\n",
        "        print(f\"{n} | {total:<15} | {linear:<18} | {non_linear}\")\n",
        "\n",
        "analyze_growth(max_n=4)\n"
      ],
      "metadata": {
        "id": "PRb_e1QX_DEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4777b887-2bf8-48a0-a84b-2752e1e7f1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Boolean functions for 2 inputs: 16\n",
            "\n",
            "Linearly separable Boolean functions (2 inputs): [1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16]\n",
            "Non-linearly separable Boolean functions (2 inputs): [7, 10]\n",
            "Count:\n",
            "  Separable: 14\n",
            "  Non-separable: 2\n",
            "\n",
            "Perceptron learning results:\n",
            "Function f1: Learned\n",
            "Function f2: Learned\n",
            "Function f3: Learned\n",
            "Function f4: Learned\n",
            "Function f5: Learned\n",
            "Function f6: Learned\n",
            "Function f7: Not Learned\n",
            "Function f8: Learned\n",
            "Function f9: Learned\n",
            "Function f10: Not Learned\n",
            "Function f11: Learned\n",
            "Function f12: Learned\n",
            "Function f13: Learned\n",
            "Function f14: Learned\n",
            "Function f15: Learned\n",
            "Function f16: Learned\n",
            "\n",
            "Reason perceptron fails:\n",
            "A single perceptron cannot learn non-linearly separable functions\n",
            "such as XOR and XNOR due to absence of a linear decision boundary.\n",
            "\n",
            "Growth of Non-Linearly Separable Boolean Functions:\n",
            "n | Total Functions | Linearly Separable | Non-Linearly Separable\n",
            "-----------------------------------------------------------------\n",
            "1 | 4               | 4                  | 0\n",
            "2 | 16              | 14                 | 2\n",
            "3 | 256             | 104                | 152\n",
            "4 | 65536           | Very Small         | Almost All\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg 7"
      ],
      "metadata": {
        "id": "EgFwq_9I-YaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q7. Design and implement a Multi-Layer Perceptron (MLP)\n",
        "capable of realizing ALL Boolean functions of two inputs.\n",
        "\n",
        "Architecture (fixed, as in the figure / hint):\n",
        "\n",
        "Inputs: x1, x2\n",
        "Hidden layer: 4 perceptrons (h1, h2, h3, h4)\n",
        "Output layer: 1 perceptron (y)\n",
        "\n",
        "Key idea:\n",
        "- Each hidden neuron fires for exactly ONE input pattern\n",
        "- Output neuron combines hidden activations to realize ANY Boolean function\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Step 1: Basic Perceptron Unit\n",
        "class Perceptron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.w = np.array(weights)\n",
        "        self.b = bias\n",
        "\n",
        "    def activate(self, x):\n",
        "        return 1 if np.dot(self.w, x) + self.b >= 0 else 0\n",
        "\n",
        "\n",
        "# Step 2: Hidden layer construction\n",
        "# Each neuron detects ONE input pattern\n",
        "# Input patterns in fixed order:\n",
        "# (0,0), (0,1), (1,0), (1,1)\n",
        "\n",
        "hidden_neurons = {\n",
        "    (0, 0): Perceptron(weights=[-1, -1], bias=0),\n",
        "    (0, 1): Perceptron(weights=[-1,  1], bias=0),\n",
        "    (1, 0): Perceptron(weights=[ 1, -1], bias=0),\n",
        "    (1, 1): Perceptron(weights=[ 1,  1], bias=-1),\n",
        "}\n",
        "\n",
        "# Step 3: MLP Model\n",
        "class BooleanMLP:\n",
        "    def __init__(self, truth_table):\n",
        "        \"\"\"\n",
        "        truth_table: list of 4 outputs for\n",
        "        [(0,0), (0,1), (1,0), (1,1)]\n",
        "        \"\"\"\n",
        "        self.truth_table = truth_table\n",
        "        self.hidden = hidden_neurons\n",
        "\n",
        "        # Output neuron weights = truth table itself\n",
        "        self.output_weights = np.array(truth_table)\n",
        "        self.output_bias = -0.5  # fires if any required hidden fires\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_out = []\n",
        "        for pattern in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "            h_out.append(self.hidden[pattern].activate(x))\n",
        "        h_out = np.array(h_out)\n",
        "\n",
        "        y = np.dot(self.output_weights, h_out) + self.output_bias\n",
        "        return 1 if y >= 0 else 0\n",
        "\n",
        "\n",
        "# Step 4: Test ALL Boolean functions\n",
        "inputs = [(0,0), (0,1), (1,0), (1,1)]\n",
        "all_boolean_functions = list(itertools.product([0,1], repeat=4))\n",
        "\n",
        "success = True\n",
        "\n",
        "for idx, func in enumerate(all_boolean_functions, 1):\n",
        "    mlp = BooleanMLP(func)\n",
        "    for x, expected in zip(inputs, func):\n",
        "        output = mlp.forward(x)\n",
        "        if output != expected:\n",
        "            success = False\n",
        "            print(f\"Function f{idx} FAILED for input {x}\")\n",
        "            break\n",
        "\n",
        "print(\"\\nResult:\")\n",
        "if success:\n",
        "    print(\"✅ MLP successfully represents ALL 16 Boolean functions\")\n",
        "else:\n",
        "    print(\"❌ Some Boolean functions failed\")\n",
        "\n",
        "\n",
        "# Step 5: Explanation Summary (printed)\n",
        "print(\"\\nExplanation:\")\n",
        "print(\"\"\"\n",
        "• Hidden layer has 4 perceptrons\n",
        "• Each hidden perceptron activates for exactly ONE input\n",
        "• This creates a one-hot encoding of the input space\n",
        "• Output perceptron linearly combines hidden activations\n",
        "• Hence ANY Boolean function can be represented\n",
        "• This overcomes the XOR limitation of a single perceptron\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2AuGCfQt0CK",
        "outputId": "87ce06dc-3c8a-4b38-8356-8b8bda9767af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function f2 FAILED for input (0, 1)\n",
            "Function f3 FAILED for input (0, 0)\n",
            "Function f4 FAILED for input (0, 0)\n",
            "Function f5 FAILED for input (0, 0)\n",
            "Function f6 FAILED for input (0, 0)\n",
            "Function f7 FAILED for input (0, 0)\n",
            "Function f8 FAILED for input (0, 0)\n",
            "Function f10 FAILED for input (0, 1)\n",
            "Function f11 FAILED for input (1, 1)\n",
            "Function f12 FAILED for input (0, 1)\n",
            "Function f13 FAILED for input (1, 1)\n",
            "Function f14 FAILED for input (1, 0)\n",
            "Function f15 FAILED for input (1, 1)\n",
            "\n",
            "Result:\n",
            "❌ Some Boolean functions failed\n",
            "\n",
            "Explanation:\n",
            "\n",
            "• Hidden layer has 4 perceptrons\n",
            "• Each hidden perceptron activates for exactly ONE input\n",
            "• This creates a one-hot encoding of the input space\n",
            "• Output perceptron linearly combines hidden activations\n",
            "• Hence ANY Boolean function can be represented\n",
            "• This overcomes the XOR limitation of a single perceptron\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "def mlp_boolean(x, hidden_weights, hidden_biases, out_weights, out_bias):\n",
        "    hidden_outputs = []\n",
        "    for w, b in zip(hidden_weights, hidden_biases):\n",
        "        hidden_outputs.append(step(np.dot(w, x) + b))\n",
        "    return step(np.dot(out_weights, hidden_outputs) + out_bias)\n",
        "\n",
        "def build_mlp(n, boolean_function):\n",
        "    inputs = list(product([0,1], repeat=n))\n",
        "\n",
        "    hidden_weights = []\n",
        "    hidden_biases = []\n",
        "\n",
        "    for inp in inputs:\n",
        "        w = [1 if bit == 1 else -1 for bit in inp]\n",
        "        b = -sum(1 for bit in inp if bit == 1) + 0.5\n",
        "        hidden_weights.append(np.array(w))\n",
        "        hidden_biases.append(b)\n",
        "\n",
        "    out_weights = np.array(boolean_function)\n",
        "    out_bias = -0.5\n",
        "\n",
        "    return hidden_weights, hidden_biases, out_weights, out_bias\n",
        "\n",
        "boolean_function = [0,1,1,0]  # XOR\n",
        "hw, hb, ow, ob = build_mlp(2, boolean_function)\n",
        "\n",
        "for x in product([0,1], repeat=2):\n",
        "    print(x, mlp_boolean(np.array(x), hw, hb, ow, ob))\n",
        "\n"
      ],
      "metadata": {
        "id": "2A0qrF3iBYcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c392d5-95ec-4fca-b922-7a8469caf838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 0) 0\n",
            "(0, 1) 1\n",
            "(1, 0) 1\n",
            "(1, 1) 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prg - 8"
      ],
      "metadata": {
        "id": "Iydy-3saCDnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "X = list(product([0,1], repeat=3))\n",
        "\n",
        "# Hidden layer (fixed)\n",
        "hidden_weights = []\n",
        "hidden_biases = []\n",
        "\n",
        "for p in X:\n",
        "    w = np.array([1 if bit else -1 for bit in p])\n",
        "    b = -sum(p) + 0.5\n",
        "    hidden_weights.append(w)\n",
        "    hidden_biases.append(b)\n",
        "\n",
        "def predict(x, out_w, out_b):\n",
        "    h = [step(np.dot(w, x) + b)\n",
        "         for w, b in zip(hidden_weights, hidden_biases)]\n",
        "    return step(np.dot(out_w, h) + out_b)\n",
        "\n",
        "# Demonstrate selected Boolean functions\n",
        "examples = {\n",
        "    \"AND\":       [0,0,0,0,0,0,0,1],\n",
        "    \"OR\":        [0,1,1,1,1,1,1,1],\n",
        "    \"XOR\":       [0,1,1,0,1,0,0,1],\n",
        "    \"CONST_1\":   [1,1,1,1,1,1,1,1]\n",
        "}\n",
        "\n",
        "for name, f in examples.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    for x, y in zip(X, f):\n",
        "        print(x, \"→\", predict(np.array(x), f, -0.5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q-fKKqNCEtG",
        "outputId": "d0e9ac19-da9f-4ceb-d63e-340702ac2736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AND\n",
            "(0, 0, 0) → 0\n",
            "(0, 0, 1) → 0\n",
            "(0, 1, 0) → 0\n",
            "(0, 1, 1) → 0\n",
            "(1, 0, 0) → 0\n",
            "(1, 0, 1) → 0\n",
            "(1, 1, 0) → 0\n",
            "(1, 1, 1) → 1\n",
            "\n",
            "OR\n",
            "(0, 0, 0) → 0\n",
            "(0, 0, 1) → 1\n",
            "(0, 1, 0) → 1\n",
            "(0, 1, 1) → 1\n",
            "(1, 0, 0) → 1\n",
            "(1, 0, 1) → 1\n",
            "(1, 1, 0) → 1\n",
            "(1, 1, 1) → 1\n",
            "\n",
            "XOR\n",
            "(0, 0, 0) → 0\n",
            "(0, 0, 1) → 1\n",
            "(0, 1, 0) → 1\n",
            "(0, 1, 1) → 0\n",
            "(1, 0, 0) → 1\n",
            "(1, 0, 1) → 0\n",
            "(1, 1, 0) → 0\n",
            "(1, 1, 1) → 1\n",
            "\n",
            "CONST_1\n",
            "(0, 0, 0) → 1\n",
            "(0, 0, 1) → 1\n",
            "(0, 1, 0) → 1\n",
            "(0, 1, 1) → 1\n",
            "(1, 0, 0) → 1\n",
            "(1, 0, 1) → 1\n",
            "(1, 1, 0) → 1\n",
            "(1, 1, 1) → 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1W-O1YZMCFJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3"
      ],
      "metadata": {
        "id": "8C4o7XBK3jKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for XOR – Effect of Learning Rate on Loss\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "\n",
        "learning_rates = [ 1.0, 1.25, 1.5, 1.75, 2]\n",
        "final_losses = []\n",
        "\n",
        "epochs = 10000\n",
        "\n",
        "\n",
        "for lr in learning_rates:\n",
        "\n",
        "    np.random.seed(42)\n",
        "\n",
        "    W1 = np.random.rand(2, 2)\n",
        "    b1 = np.random.rand(1, 2)\n",
        "\n",
        "    W2 = np.random.rand(2, 1)\n",
        "    b2 = np.random.rand(1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        hidden_input = np.dot(X, W1) + b1\n",
        "        hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "        final_input = np.dot(hidden_output, W2) + b2\n",
        "        y_pred = sigmoid(final_input)\n",
        "\n",
        "        error = y - y_pred\n",
        "        loss = np.mean(error ** 2)\n",
        "\n",
        "        d_output = error * sigmoid_derivative(y_pred)\n",
        "        d_hidden = d_output.dot(W2.T) * sigmoid_derivative(hidden_output)\n",
        "\n",
        "        W2 += hidden_output.T.dot(d_output) * lr\n",
        "        b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "\n",
        "        W1 += X.T.dot(d_hidden) * lr\n",
        "        b1 += np.sum(d_hidden, axis=0, keepdims=True) * lr\n",
        "\n",
        "    final_losses.append(loss)\n",
        "    print(f\"Learning Rate: {lr}, Final Loss: {loss:.6f}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(learning_rates, final_losses, marker='o')\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Final Loss (MSE)\")\n",
        "plt.title(\"Effect of Learning Rate on XOR MLP Training\")\n",
        "plt.xscale(\"log\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "7J-RuHGE6Yw8",
        "outputId": "94bd0d2f-7442-4da0-e048-201960fdb50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 1.0, Final Loss: 0.000135\n",
            "Learning Rate: 1.25, Final Loss: 0.000106\n",
            "Learning Rate: 1.5, Final Loss: 0.000087\n",
            "Learning Rate: 1.75, Final Loss: 0.000074\n",
            "Learning Rate: 2, Final Loss: 0.000064\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)\n",
        "\n",
        "perceptron = Perceptron()\n",
        "\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkSLQ3aF3kBm",
        "outputId": "8daf7d93-d676-4ac5-9196-93dd8e856ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X,y = load_breast_cancer(return_X_y=True)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "perceptron = Perceptron(max_iter=400, verbose=True, penalty='l1')\n",
        "perceptron.fit(x_train,y_train)\n",
        "y_pred = perceptron.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyNJdC4B9AYq",
        "outputId": "2030ba8a-8666-4e88-855c-499e670a4460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 5460.05, NNZs: 30, Bias: 53.000000, T: 398, Avg. loss: 215316.586429\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 8432.30, NNZs: 29, Bias: 93.000000, T: 796, Avg. loss: 152255.587266\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 10002.64, NNZs: 30, Bias: 115.000000, T: 1194, Avg. loss: 120801.766466\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 11543.27, NNZs: 29, Bias: 133.000000, T: 1592, Avg. loss: 90094.178472\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 13172.77, NNZs: 28, Bias: 156.000000, T: 1990, Avg. loss: 112926.792461\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 14254.99, NNZs: 28, Bias: 172.000000, T: 2388, Avg. loss: 81806.595351\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 15632.16, NNZs: 29, Bias: 188.000000, T: 2786, Avg. loss: 95144.955505\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 16582.02, NNZs: 28, Bias: 205.000000, T: 3184, Avg. loss: 88204.057719\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 17404.81, NNZs: 28, Bias: 216.000000, T: 3582, Avg. loss: 81697.074252\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 18021.68, NNZs: 28, Bias: 228.000000, T: 3980, Avg. loss: 64520.416561\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 18406.72, NNZs: 28, Bias: 235.000000, T: 4378, Avg. loss: 74203.699108\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 19044.26, NNZs: 28, Bias: 243.000000, T: 4776, Avg. loss: 76074.342707\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 19740.91, NNZs: 29, Bias: 252.000000, T: 5174, Avg. loss: 82192.579286\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 20023.62, NNZs: 29, Bias: 257.000000, T: 5572, Avg. loss: 60879.830446\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 20356.25, NNZs: 28, Bias: 265.000000, T: 5970, Avg. loss: 76971.873796\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 20728.36, NNZs: 28, Bias: 271.000000, T: 6368, Avg. loss: 62757.868573\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 21037.28, NNZs: 29, Bias: 274.000000, T: 6766, Avg. loss: 74009.461774\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 21283.96, NNZs: 28, Bias: 282.000000, T: 7164, Avg. loss: 64538.271988\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 21396.29, NNZs: 28, Bias: 285.000000, T: 7562, Avg. loss: 68534.985306\n",
            "Total training time: 0.01 seconds.\n",
            "Convergence after 19 epochs took 0.01 seconds\n",
            "Accuracy: 0.935672514619883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate whether perceptron learns automatic feature engineering\n"
      ],
      "metadata": {
        "id": "ZY8CLjzoCRE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Duplicate features implements model performance ?"
      ],
      "metadata": {
        "id": "vxesTll3Igjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 4"
      ],
      "metadata": {
        "id": "iCMb4XO9IkDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#USING OPTIMIZATION ALGO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import altair as alt\n",
        "import tensorflow as tf # Import TensorFlow\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# expected values\n",
        "y = np.array([[0, 1, 1, 0]]).T\n",
        "\n",
        "# features\n",
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]]).T\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy', 'mean_squared_error'])\n",
        "\n",
        "history = model.fit(X, y, epochs=750, verbose=0)\n",
        "\n",
        "\n",
        "errors = history.history['loss']\n",
        "\n",
        "df2 = pd.DataFrame({\"errors\":errors, \"time-step\": np.arange(0, len(errors))})\n",
        "\n",
        "alt.Chart(df2).mark_line().encode(x=\"time-step\", y=\"errors\").properties(title='Chart 3')\n",
        "\n",
        "\n",
        "y_pred = model.predict(X).round()\n",
        "num_correct_predictions = (y_pred == y).sum()\n",
        "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
        "print('Multi-layer perceptron accuracy: %.2f%%' % accuracy)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muC1upca7tfL",
        "outputId": "214137aa-0ef8-462d-a08a-f9a0c768c305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Multi-layer perceptron accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy history\n",
        "accuracy_history = history.history['binary_accuracy']\n",
        "\n",
        "# Create DataFrame for accuracy\n",
        "df_acc = pd.DataFrame({\n",
        "    \"accuracy\": accuracy_history,\n",
        "    \"epoch\": np.arange(1, len(accuracy_history) + 1)\n",
        "})\n",
        "\n",
        "# Plot accuracy over epochs\n",
        "alt.Chart(df_acc).mark_line().encode(\n",
        "    x=\"epoch\",\n",
        "    y=\"accuracy\"\n",
        ").properties(\n",
        "    title='Model Accuracy Over Epochs'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "wf0O7eec-NF0",
        "outputId": "e2e111e3-5a5e-4d68-b0f1-9a67c8bcde94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-7304cf8223d640c4b489a82742297236.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-7304cf8223d640c4b489a82742297236.vega-embed details,\n",
              "  #altair-viz-7304cf8223d640c4b489a82742297236.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-7304cf8223d640c4b489a82742297236\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-7304cf8223d640c4b489a82742297236\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-7304cf8223d640c4b489a82742297236\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e5fcfc362d2e1b3cf6fc8178b62384d0\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Model Accuracy Over Epochs\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-e5fcfc362d2e1b3cf6fc8178b62384d0\": [{\"accuracy\": 0.5, \"epoch\": 1}, {\"accuracy\": 0.5, \"epoch\": 2}, {\"accuracy\": 0.5, \"epoch\": 3}, {\"accuracy\": 0.5, \"epoch\": 4}, {\"accuracy\": 0.5, \"epoch\": 5}, {\"accuracy\": 0.5, \"epoch\": 6}, {\"accuracy\": 0.5, \"epoch\": 7}, {\"accuracy\": 0.5, \"epoch\": 8}, {\"accuracy\": 0.5, \"epoch\": 9}, {\"accuracy\": 0.5, \"epoch\": 10}, {\"accuracy\": 0.5, \"epoch\": 11}, {\"accuracy\": 0.5, \"epoch\": 12}, {\"accuracy\": 0.5, \"epoch\": 13}, {\"accuracy\": 0.5, \"epoch\": 14}, {\"accuracy\": 0.5, \"epoch\": 15}, {\"accuracy\": 0.5, \"epoch\": 16}, {\"accuracy\": 0.5, \"epoch\": 17}, {\"accuracy\": 0.5, \"epoch\": 18}, {\"accuracy\": 0.5, \"epoch\": 19}, {\"accuracy\": 0.5, \"epoch\": 20}, {\"accuracy\": 0.5, \"epoch\": 21}, {\"accuracy\": 0.5, \"epoch\": 22}, {\"accuracy\": 0.5, \"epoch\": 23}, {\"accuracy\": 0.5, \"epoch\": 24}, {\"accuracy\": 0.5, \"epoch\": 25}, {\"accuracy\": 0.5, \"epoch\": 26}, {\"accuracy\": 0.5, \"epoch\": 27}, {\"accuracy\": 0.5, \"epoch\": 28}, {\"accuracy\": 0.5, \"epoch\": 29}, {\"accuracy\": 0.5, \"epoch\": 30}, {\"accuracy\": 0.5, \"epoch\": 31}, {\"accuracy\": 0.5, \"epoch\": 32}, {\"accuracy\": 0.5, \"epoch\": 33}, {\"accuracy\": 0.5, \"epoch\": 34}, {\"accuracy\": 0.5, \"epoch\": 35}, {\"accuracy\": 0.5, \"epoch\": 36}, {\"accuracy\": 0.5, \"epoch\": 37}, {\"accuracy\": 0.25, \"epoch\": 38}, {\"accuracy\": 0.25, \"epoch\": 39}, {\"accuracy\": 0.25, \"epoch\": 40}, {\"accuracy\": 0.25, \"epoch\": 41}, {\"accuracy\": 0.25, \"epoch\": 42}, {\"accuracy\": 0.25, \"epoch\": 43}, {\"accuracy\": 0.25, \"epoch\": 44}, {\"accuracy\": 0.25, \"epoch\": 45}, {\"accuracy\": 0.25, \"epoch\": 46}, {\"accuracy\": 0.25, \"epoch\": 47}, {\"accuracy\": 0.25, \"epoch\": 48}, {\"accuracy\": 0.25, \"epoch\": 49}, {\"accuracy\": 0.25, \"epoch\": 50}, {\"accuracy\": 0.25, \"epoch\": 51}, {\"accuracy\": 0.25, \"epoch\": 52}, {\"accuracy\": 0.25, \"epoch\": 53}, {\"accuracy\": 0.25, \"epoch\": 54}, {\"accuracy\": 0.25, \"epoch\": 55}, {\"accuracy\": 0.25, \"epoch\": 56}, {\"accuracy\": 0.25, \"epoch\": 57}, {\"accuracy\": 0.5, \"epoch\": 58}, {\"accuracy\": 0.5, \"epoch\": 59}, {\"accuracy\": 0.5, \"epoch\": 60}, {\"accuracy\": 0.5, \"epoch\": 61}, {\"accuracy\": 0.5, \"epoch\": 62}, {\"accuracy\": 0.5, \"epoch\": 63}, {\"accuracy\": 0.5, \"epoch\": 64}, {\"accuracy\": 0.5, \"epoch\": 65}, {\"accuracy\": 0.5, \"epoch\": 66}, {\"accuracy\": 0.5, \"epoch\": 67}, {\"accuracy\": 0.5, \"epoch\": 68}, {\"accuracy\": 0.5, \"epoch\": 69}, {\"accuracy\": 0.5, \"epoch\": 70}, {\"accuracy\": 0.5, \"epoch\": 71}, {\"accuracy\": 0.5, \"epoch\": 72}, {\"accuracy\": 0.5, \"epoch\": 73}, {\"accuracy\": 0.75, \"epoch\": 74}, {\"accuracy\": 0.75, \"epoch\": 75}, {\"accuracy\": 0.75, \"epoch\": 76}, {\"accuracy\": 0.75, \"epoch\": 77}, {\"accuracy\": 0.75, \"epoch\": 78}, {\"accuracy\": 0.75, \"epoch\": 79}, {\"accuracy\": 0.75, \"epoch\": 80}, {\"accuracy\": 0.75, \"epoch\": 81}, {\"accuracy\": 0.75, \"epoch\": 82}, {\"accuracy\": 0.75, \"epoch\": 83}, {\"accuracy\": 0.75, \"epoch\": 84}, {\"accuracy\": 0.75, \"epoch\": 85}, {\"accuracy\": 0.75, \"epoch\": 86}, {\"accuracy\": 0.75, \"epoch\": 87}, {\"accuracy\": 0.75, \"epoch\": 88}, {\"accuracy\": 0.75, \"epoch\": 89}, {\"accuracy\": 0.75, \"epoch\": 90}, {\"accuracy\": 0.75, \"epoch\": 91}, {\"accuracy\": 0.75, \"epoch\": 92}, {\"accuracy\": 0.5, \"epoch\": 93}, {\"accuracy\": 0.5, \"epoch\": 94}, {\"accuracy\": 0.5, \"epoch\": 95}, {\"accuracy\": 0.5, \"epoch\": 96}, {\"accuracy\": 0.5, \"epoch\": 97}, {\"accuracy\": 0.5, \"epoch\": 98}, {\"accuracy\": 0.5, \"epoch\": 99}, {\"accuracy\": 0.5, \"epoch\": 100}, {\"accuracy\": 0.5, \"epoch\": 101}, {\"accuracy\": 0.5, \"epoch\": 102}, {\"accuracy\": 0.5, \"epoch\": 103}, {\"accuracy\": 0.5, \"epoch\": 104}, {\"accuracy\": 0.5, \"epoch\": 105}, {\"accuracy\": 0.5, \"epoch\": 106}, {\"accuracy\": 0.5, \"epoch\": 107}, {\"accuracy\": 0.5, \"epoch\": 108}, {\"accuracy\": 0.5, \"epoch\": 109}, {\"accuracy\": 0.5, \"epoch\": 110}, {\"accuracy\": 0.5, \"epoch\": 111}, {\"accuracy\": 0.5, \"epoch\": 112}, {\"accuracy\": 0.5, \"epoch\": 113}, {\"accuracy\": 0.5, \"epoch\": 114}, {\"accuracy\": 0.5, \"epoch\": 115}, {\"accuracy\": 0.5, \"epoch\": 116}, {\"accuracy\": 0.5, \"epoch\": 117}, {\"accuracy\": 0.5, \"epoch\": 118}, {\"accuracy\": 0.5, \"epoch\": 119}, {\"accuracy\": 0.5, \"epoch\": 120}, {\"accuracy\": 0.5, \"epoch\": 121}, {\"accuracy\": 0.5, \"epoch\": 122}, {\"accuracy\": 0.5, \"epoch\": 123}, {\"accuracy\": 0.5, \"epoch\": 124}, {\"accuracy\": 0.5, \"epoch\": 125}, {\"accuracy\": 0.5, \"epoch\": 126}, {\"accuracy\": 0.5, \"epoch\": 127}, {\"accuracy\": 0.5, \"epoch\": 128}, {\"accuracy\": 0.5, \"epoch\": 129}, {\"accuracy\": 0.5, \"epoch\": 130}, {\"accuracy\": 0.5, \"epoch\": 131}, {\"accuracy\": 0.5, \"epoch\": 132}, {\"accuracy\": 0.5, \"epoch\": 133}, {\"accuracy\": 0.5, \"epoch\": 134}, {\"accuracy\": 0.5, \"epoch\": 135}, {\"accuracy\": 0.5, \"epoch\": 136}, {\"accuracy\": 0.5, \"epoch\": 137}, {\"accuracy\": 0.5, \"epoch\": 138}, {\"accuracy\": 0.5, \"epoch\": 139}, {\"accuracy\": 0.5, \"epoch\": 140}, {\"accuracy\": 0.5, \"epoch\": 141}, {\"accuracy\": 0.5, \"epoch\": 142}, {\"accuracy\": 0.5, \"epoch\": 143}, {\"accuracy\": 0.5, \"epoch\": 144}, {\"accuracy\": 0.5, \"epoch\": 145}, {\"accuracy\": 0.5, \"epoch\": 146}, {\"accuracy\": 0.5, \"epoch\": 147}, {\"accuracy\": 0.5, \"epoch\": 148}, {\"accuracy\": 0.5, \"epoch\": 149}, {\"accuracy\": 0.5, \"epoch\": 150}, {\"accuracy\": 0.5, \"epoch\": 151}, {\"accuracy\": 0.5, \"epoch\": 152}, {\"accuracy\": 0.5, \"epoch\": 153}, {\"accuracy\": 0.5, \"epoch\": 154}, {\"accuracy\": 0.5, \"epoch\": 155}, {\"accuracy\": 0.5, \"epoch\": 156}, {\"accuracy\": 0.5, \"epoch\": 157}, {\"accuracy\": 0.5, \"epoch\": 158}, {\"accuracy\": 0.5, \"epoch\": 159}, {\"accuracy\": 0.5, \"epoch\": 160}, {\"accuracy\": 0.5, \"epoch\": 161}, {\"accuracy\": 0.5, \"epoch\": 162}, {\"accuracy\": 0.5, \"epoch\": 163}, {\"accuracy\": 0.5, \"epoch\": 164}, {\"accuracy\": 0.5, \"epoch\": 165}, {\"accuracy\": 0.5, \"epoch\": 166}, {\"accuracy\": 0.5, \"epoch\": 167}, {\"accuracy\": 0.5, \"epoch\": 168}, {\"accuracy\": 0.5, \"epoch\": 169}, {\"accuracy\": 0.5, \"epoch\": 170}, {\"accuracy\": 0.5, \"epoch\": 171}, {\"accuracy\": 0.75, \"epoch\": 172}, {\"accuracy\": 0.75, \"epoch\": 173}, {\"accuracy\": 0.75, \"epoch\": 174}, {\"accuracy\": 0.75, \"epoch\": 175}, {\"accuracy\": 0.75, \"epoch\": 176}, {\"accuracy\": 0.75, \"epoch\": 177}, {\"accuracy\": 0.75, \"epoch\": 178}, {\"accuracy\": 0.75, \"epoch\": 179}, {\"accuracy\": 0.75, \"epoch\": 180}, {\"accuracy\": 0.75, \"epoch\": 181}, {\"accuracy\": 0.75, \"epoch\": 182}, {\"accuracy\": 0.75, \"epoch\": 183}, {\"accuracy\": 0.75, \"epoch\": 184}, {\"accuracy\": 0.75, \"epoch\": 185}, {\"accuracy\": 0.75, \"epoch\": 186}, {\"accuracy\": 0.75, \"epoch\": 187}, {\"accuracy\": 0.75, \"epoch\": 188}, {\"accuracy\": 0.75, \"epoch\": 189}, {\"accuracy\": 0.75, \"epoch\": 190}, {\"accuracy\": 0.75, \"epoch\": 191}, {\"accuracy\": 0.75, \"epoch\": 192}, {\"accuracy\": 0.75, \"epoch\": 193}, {\"accuracy\": 0.75, \"epoch\": 194}, {\"accuracy\": 0.75, \"epoch\": 195}, {\"accuracy\": 0.75, \"epoch\": 196}, {\"accuracy\": 0.75, \"epoch\": 197}, {\"accuracy\": 0.75, \"epoch\": 198}, {\"accuracy\": 0.75, \"epoch\": 199}, {\"accuracy\": 0.75, \"epoch\": 200}, {\"accuracy\": 0.75, \"epoch\": 201}, {\"accuracy\": 0.75, \"epoch\": 202}, {\"accuracy\": 0.75, \"epoch\": 203}, {\"accuracy\": 0.75, \"epoch\": 204}, {\"accuracy\": 0.75, \"epoch\": 205}, {\"accuracy\": 0.75, \"epoch\": 206}, {\"accuracy\": 0.75, \"epoch\": 207}, {\"accuracy\": 0.75, \"epoch\": 208}, {\"accuracy\": 0.75, \"epoch\": 209}, {\"accuracy\": 0.75, \"epoch\": 210}, {\"accuracy\": 0.75, \"epoch\": 211}, {\"accuracy\": 0.75, \"epoch\": 212}, {\"accuracy\": 0.75, \"epoch\": 213}, {\"accuracy\": 0.75, \"epoch\": 214}, {\"accuracy\": 0.75, \"epoch\": 215}, {\"accuracy\": 0.75, \"epoch\": 216}, {\"accuracy\": 0.75, \"epoch\": 217}, {\"accuracy\": 0.75, \"epoch\": 218}, {\"accuracy\": 0.75, \"epoch\": 219}, {\"accuracy\": 0.75, \"epoch\": 220}, {\"accuracy\": 0.75, \"epoch\": 221}, {\"accuracy\": 0.75, \"epoch\": 222}, {\"accuracy\": 0.75, \"epoch\": 223}, {\"accuracy\": 0.75, \"epoch\": 224}, {\"accuracy\": 0.75, \"epoch\": 225}, {\"accuracy\": 0.75, \"epoch\": 226}, {\"accuracy\": 0.75, \"epoch\": 227}, {\"accuracy\": 0.75, \"epoch\": 228}, {\"accuracy\": 0.75, \"epoch\": 229}, {\"accuracy\": 0.75, \"epoch\": 230}, {\"accuracy\": 0.75, \"epoch\": 231}, {\"accuracy\": 0.75, \"epoch\": 232}, {\"accuracy\": 0.75, \"epoch\": 233}, {\"accuracy\": 0.75, \"epoch\": 234}, {\"accuracy\": 0.75, \"epoch\": 235}, {\"accuracy\": 0.75, \"epoch\": 236}, {\"accuracy\": 0.75, \"epoch\": 237}, {\"accuracy\": 0.75, \"epoch\": 238}, {\"accuracy\": 0.75, \"epoch\": 239}, {\"accuracy\": 0.75, \"epoch\": 240}, {\"accuracy\": 0.75, \"epoch\": 241}, {\"accuracy\": 0.75, \"epoch\": 242}, {\"accuracy\": 0.75, \"epoch\": 243}, {\"accuracy\": 0.75, \"epoch\": 244}, {\"accuracy\": 0.75, \"epoch\": 245}, {\"accuracy\": 0.75, \"epoch\": 246}, {\"accuracy\": 0.75, \"epoch\": 247}, {\"accuracy\": 0.75, \"epoch\": 248}, {\"accuracy\": 0.75, \"epoch\": 249}, {\"accuracy\": 0.75, \"epoch\": 250}, {\"accuracy\": 0.75, \"epoch\": 251}, {\"accuracy\": 0.75, \"epoch\": 252}, {\"accuracy\": 0.75, \"epoch\": 253}, {\"accuracy\": 0.75, \"epoch\": 254}, {\"accuracy\": 0.75, \"epoch\": 255}, {\"accuracy\": 0.75, \"epoch\": 256}, {\"accuracy\": 0.75, \"epoch\": 257}, {\"accuracy\": 0.75, \"epoch\": 258}, {\"accuracy\": 0.75, \"epoch\": 259}, {\"accuracy\": 0.75, \"epoch\": 260}, {\"accuracy\": 0.75, \"epoch\": 261}, {\"accuracy\": 0.75, \"epoch\": 262}, {\"accuracy\": 0.75, \"epoch\": 263}, {\"accuracy\": 0.75, \"epoch\": 264}, {\"accuracy\": 0.75, \"epoch\": 265}, {\"accuracy\": 0.75, \"epoch\": 266}, {\"accuracy\": 0.75, \"epoch\": 267}, {\"accuracy\": 0.75, \"epoch\": 268}, {\"accuracy\": 0.75, \"epoch\": 269}, {\"accuracy\": 0.75, \"epoch\": 270}, {\"accuracy\": 0.75, \"epoch\": 271}, {\"accuracy\": 0.75, \"epoch\": 272}, {\"accuracy\": 0.75, \"epoch\": 273}, {\"accuracy\": 0.75, \"epoch\": 274}, {\"accuracy\": 0.75, \"epoch\": 275}, {\"accuracy\": 0.75, \"epoch\": 276}, {\"accuracy\": 0.75, \"epoch\": 277}, {\"accuracy\": 0.75, \"epoch\": 278}, {\"accuracy\": 0.75, \"epoch\": 279}, {\"accuracy\": 0.75, \"epoch\": 280}, {\"accuracy\": 0.75, \"epoch\": 281}, {\"accuracy\": 0.75, \"epoch\": 282}, {\"accuracy\": 0.75, \"epoch\": 283}, {\"accuracy\": 0.75, \"epoch\": 284}, {\"accuracy\": 0.75, \"epoch\": 285}, {\"accuracy\": 0.75, \"epoch\": 286}, {\"accuracy\": 0.75, \"epoch\": 287}, {\"accuracy\": 0.75, \"epoch\": 288}, {\"accuracy\": 0.75, \"epoch\": 289}, {\"accuracy\": 0.75, \"epoch\": 290}, {\"accuracy\": 0.75, \"epoch\": 291}, {\"accuracy\": 0.75, \"epoch\": 292}, {\"accuracy\": 0.75, \"epoch\": 293}, {\"accuracy\": 0.75, \"epoch\": 294}, {\"accuracy\": 0.75, \"epoch\": 295}, {\"accuracy\": 0.75, \"epoch\": 296}, {\"accuracy\": 0.75, \"epoch\": 297}, {\"accuracy\": 0.75, \"epoch\": 298}, {\"accuracy\": 0.75, \"epoch\": 299}, {\"accuracy\": 0.75, \"epoch\": 300}, {\"accuracy\": 0.75, \"epoch\": 301}, {\"accuracy\": 0.75, \"epoch\": 302}, {\"accuracy\": 0.75, \"epoch\": 303}, {\"accuracy\": 0.75, \"epoch\": 304}, {\"accuracy\": 0.75, \"epoch\": 305}, {\"accuracy\": 0.75, \"epoch\": 306}, {\"accuracy\": 0.75, \"epoch\": 307}, {\"accuracy\": 0.75, \"epoch\": 308}, {\"accuracy\": 0.75, \"epoch\": 309}, {\"accuracy\": 0.75, \"epoch\": 310}, {\"accuracy\": 0.75, \"epoch\": 311}, {\"accuracy\": 0.75, \"epoch\": 312}, {\"accuracy\": 0.75, \"epoch\": 313}, {\"accuracy\": 0.75, \"epoch\": 314}, {\"accuracy\": 0.75, \"epoch\": 315}, {\"accuracy\": 0.75, \"epoch\": 316}, {\"accuracy\": 0.75, \"epoch\": 317}, {\"accuracy\": 0.75, \"epoch\": 318}, {\"accuracy\": 0.75, \"epoch\": 319}, {\"accuracy\": 0.75, \"epoch\": 320}, {\"accuracy\": 0.75, \"epoch\": 321}, {\"accuracy\": 0.75, \"epoch\": 322}, {\"accuracy\": 0.75, \"epoch\": 323}, {\"accuracy\": 0.75, \"epoch\": 324}, {\"accuracy\": 0.75, \"epoch\": 325}, {\"accuracy\": 0.75, \"epoch\": 326}, {\"accuracy\": 0.75, \"epoch\": 327}, {\"accuracy\": 0.75, \"epoch\": 328}, {\"accuracy\": 0.75, \"epoch\": 329}, {\"accuracy\": 0.75, \"epoch\": 330}, {\"accuracy\": 0.75, \"epoch\": 331}, {\"accuracy\": 0.75, \"epoch\": 332}, {\"accuracy\": 0.75, \"epoch\": 333}, {\"accuracy\": 0.75, \"epoch\": 334}, {\"accuracy\": 0.75, \"epoch\": 335}, {\"accuracy\": 0.75, \"epoch\": 336}, {\"accuracy\": 0.75, \"epoch\": 337}, {\"accuracy\": 0.75, \"epoch\": 338}, {\"accuracy\": 0.75, \"epoch\": 339}, {\"accuracy\": 0.75, \"epoch\": 340}, {\"accuracy\": 0.75, \"epoch\": 341}, {\"accuracy\": 0.75, \"epoch\": 342}, {\"accuracy\": 0.75, \"epoch\": 343}, {\"accuracy\": 0.75, \"epoch\": 344}, {\"accuracy\": 0.75, \"epoch\": 345}, {\"accuracy\": 0.75, \"epoch\": 346}, {\"accuracy\": 0.75, \"epoch\": 347}, {\"accuracy\": 0.75, \"epoch\": 348}, {\"accuracy\": 0.75, \"epoch\": 349}, {\"accuracy\": 0.75, \"epoch\": 350}, {\"accuracy\": 0.75, \"epoch\": 351}, {\"accuracy\": 0.75, \"epoch\": 352}, {\"accuracy\": 0.75, \"epoch\": 353}, {\"accuracy\": 0.75, \"epoch\": 354}, {\"accuracy\": 0.75, \"epoch\": 355}, {\"accuracy\": 0.75, \"epoch\": 356}, {\"accuracy\": 0.75, \"epoch\": 357}, {\"accuracy\": 0.75, \"epoch\": 358}, {\"accuracy\": 0.75, \"epoch\": 359}, {\"accuracy\": 0.75, \"epoch\": 360}, {\"accuracy\": 0.75, \"epoch\": 361}, {\"accuracy\": 0.75, \"epoch\": 362}, {\"accuracy\": 0.75, \"epoch\": 363}, {\"accuracy\": 0.75, \"epoch\": 364}, {\"accuracy\": 0.75, \"epoch\": 365}, {\"accuracy\": 0.75, \"epoch\": 366}, {\"accuracy\": 0.75, \"epoch\": 367}, {\"accuracy\": 0.75, \"epoch\": 368}, {\"accuracy\": 0.75, \"epoch\": 369}, {\"accuracy\": 0.75, \"epoch\": 370}, {\"accuracy\": 0.75, \"epoch\": 371}, {\"accuracy\": 0.75, \"epoch\": 372}, {\"accuracy\": 0.75, \"epoch\": 373}, {\"accuracy\": 0.75, \"epoch\": 374}, {\"accuracy\": 0.75, \"epoch\": 375}, {\"accuracy\": 0.75, \"epoch\": 376}, {\"accuracy\": 0.75, \"epoch\": 377}, {\"accuracy\": 0.75, \"epoch\": 378}, {\"accuracy\": 0.75, \"epoch\": 379}, {\"accuracy\": 0.75, \"epoch\": 380}, {\"accuracy\": 0.75, \"epoch\": 381}, {\"accuracy\": 0.75, \"epoch\": 382}, {\"accuracy\": 0.75, \"epoch\": 383}, {\"accuracy\": 0.75, \"epoch\": 384}, {\"accuracy\": 0.75, \"epoch\": 385}, {\"accuracy\": 0.75, \"epoch\": 386}, {\"accuracy\": 0.75, \"epoch\": 387}, {\"accuracy\": 0.75, \"epoch\": 388}, {\"accuracy\": 0.75, \"epoch\": 389}, {\"accuracy\": 0.75, \"epoch\": 390}, {\"accuracy\": 0.75, \"epoch\": 391}, {\"accuracy\": 0.75, \"epoch\": 392}, {\"accuracy\": 0.75, \"epoch\": 393}, {\"accuracy\": 0.75, \"epoch\": 394}, {\"accuracy\": 0.75, \"epoch\": 395}, {\"accuracy\": 0.75, \"epoch\": 396}, {\"accuracy\": 0.75, \"epoch\": 397}, {\"accuracy\": 0.75, \"epoch\": 398}, {\"accuracy\": 0.75, \"epoch\": 399}, {\"accuracy\": 0.75, \"epoch\": 400}, {\"accuracy\": 0.75, \"epoch\": 401}, {\"accuracy\": 0.75, \"epoch\": 402}, {\"accuracy\": 0.75, \"epoch\": 403}, {\"accuracy\": 0.75, \"epoch\": 404}, {\"accuracy\": 0.75, \"epoch\": 405}, {\"accuracy\": 0.75, \"epoch\": 406}, {\"accuracy\": 0.75, \"epoch\": 407}, {\"accuracy\": 0.75, \"epoch\": 408}, {\"accuracy\": 0.75, \"epoch\": 409}, {\"accuracy\": 0.75, \"epoch\": 410}, {\"accuracy\": 0.75, \"epoch\": 411}, {\"accuracy\": 0.75, \"epoch\": 412}, {\"accuracy\": 0.75, \"epoch\": 413}, {\"accuracy\": 0.75, \"epoch\": 414}, {\"accuracy\": 0.75, \"epoch\": 415}, {\"accuracy\": 0.75, \"epoch\": 416}, {\"accuracy\": 0.75, \"epoch\": 417}, {\"accuracy\": 0.75, \"epoch\": 418}, {\"accuracy\": 0.75, \"epoch\": 419}, {\"accuracy\": 0.75, \"epoch\": 420}, {\"accuracy\": 0.75, \"epoch\": 421}, {\"accuracy\": 0.75, \"epoch\": 422}, {\"accuracy\": 0.75, \"epoch\": 423}, {\"accuracy\": 0.75, \"epoch\": 424}, {\"accuracy\": 0.75, \"epoch\": 425}, {\"accuracy\": 0.75, \"epoch\": 426}, {\"accuracy\": 0.75, \"epoch\": 427}, {\"accuracy\": 0.75, \"epoch\": 428}, {\"accuracy\": 0.75, \"epoch\": 429}, {\"accuracy\": 0.75, \"epoch\": 430}, {\"accuracy\": 0.75, \"epoch\": 431}, {\"accuracy\": 0.75, \"epoch\": 432}, {\"accuracy\": 0.75, \"epoch\": 433}, {\"accuracy\": 0.75, \"epoch\": 434}, {\"accuracy\": 0.75, \"epoch\": 435}, {\"accuracy\": 0.75, \"epoch\": 436}, {\"accuracy\": 0.75, \"epoch\": 437}, {\"accuracy\": 0.75, \"epoch\": 438}, {\"accuracy\": 0.75, \"epoch\": 439}, {\"accuracy\": 0.75, \"epoch\": 440}, {\"accuracy\": 0.75, \"epoch\": 441}, {\"accuracy\": 0.75, \"epoch\": 442}, {\"accuracy\": 0.75, \"epoch\": 443}, {\"accuracy\": 0.75, \"epoch\": 444}, {\"accuracy\": 0.75, \"epoch\": 445}, {\"accuracy\": 0.75, \"epoch\": 446}, {\"accuracy\": 0.75, \"epoch\": 447}, {\"accuracy\": 0.75, \"epoch\": 448}, {\"accuracy\": 0.75, \"epoch\": 449}, {\"accuracy\": 0.75, \"epoch\": 450}, {\"accuracy\": 0.75, \"epoch\": 451}, {\"accuracy\": 0.75, \"epoch\": 452}, {\"accuracy\": 0.75, \"epoch\": 453}, {\"accuracy\": 0.75, \"epoch\": 454}, {\"accuracy\": 0.75, \"epoch\": 455}, {\"accuracy\": 0.75, \"epoch\": 456}, {\"accuracy\": 0.75, \"epoch\": 457}, {\"accuracy\": 0.75, \"epoch\": 458}, {\"accuracy\": 0.75, \"epoch\": 459}, {\"accuracy\": 0.75, \"epoch\": 460}, {\"accuracy\": 0.75, \"epoch\": 461}, {\"accuracy\": 0.75, \"epoch\": 462}, {\"accuracy\": 0.75, \"epoch\": 463}, {\"accuracy\": 0.75, \"epoch\": 464}, {\"accuracy\": 0.75, \"epoch\": 465}, {\"accuracy\": 0.75, \"epoch\": 466}, {\"accuracy\": 0.75, \"epoch\": 467}, {\"accuracy\": 0.75, \"epoch\": 468}, {\"accuracy\": 0.75, \"epoch\": 469}, {\"accuracy\": 0.75, \"epoch\": 470}, {\"accuracy\": 0.75, \"epoch\": 471}, {\"accuracy\": 0.75, \"epoch\": 472}, {\"accuracy\": 0.75, \"epoch\": 473}, {\"accuracy\": 0.75, \"epoch\": 474}, {\"accuracy\": 0.75, \"epoch\": 475}, {\"accuracy\": 0.75, \"epoch\": 476}, {\"accuracy\": 0.75, \"epoch\": 477}, {\"accuracy\": 0.75, \"epoch\": 478}, {\"accuracy\": 0.75, \"epoch\": 479}, {\"accuracy\": 0.75, \"epoch\": 480}, {\"accuracy\": 0.75, \"epoch\": 481}, {\"accuracy\": 0.75, \"epoch\": 482}, {\"accuracy\": 0.75, \"epoch\": 483}, {\"accuracy\": 0.75, \"epoch\": 484}, {\"accuracy\": 0.75, \"epoch\": 485}, {\"accuracy\": 0.75, \"epoch\": 486}, {\"accuracy\": 0.75, \"epoch\": 487}, {\"accuracy\": 0.75, \"epoch\": 488}, {\"accuracy\": 0.75, \"epoch\": 489}, {\"accuracy\": 0.75, \"epoch\": 490}, {\"accuracy\": 0.75, \"epoch\": 491}, {\"accuracy\": 0.75, \"epoch\": 492}, {\"accuracy\": 0.75, \"epoch\": 493}, {\"accuracy\": 0.75, \"epoch\": 494}, {\"accuracy\": 0.75, \"epoch\": 495}, {\"accuracy\": 0.75, \"epoch\": 496}, {\"accuracy\": 0.75, \"epoch\": 497}, {\"accuracy\": 0.75, \"epoch\": 498}, {\"accuracy\": 0.75, \"epoch\": 499}, {\"accuracy\": 0.75, \"epoch\": 500}, {\"accuracy\": 0.75, \"epoch\": 501}, {\"accuracy\": 0.75, \"epoch\": 502}, {\"accuracy\": 0.75, \"epoch\": 503}, {\"accuracy\": 0.75, \"epoch\": 504}, {\"accuracy\": 0.75, \"epoch\": 505}, {\"accuracy\": 0.75, \"epoch\": 506}, {\"accuracy\": 0.75, \"epoch\": 507}, {\"accuracy\": 0.75, \"epoch\": 508}, {\"accuracy\": 0.75, \"epoch\": 509}, {\"accuracy\": 0.75, \"epoch\": 510}, {\"accuracy\": 0.75, \"epoch\": 511}, {\"accuracy\": 0.75, \"epoch\": 512}, {\"accuracy\": 0.75, \"epoch\": 513}, {\"accuracy\": 0.75, \"epoch\": 514}, {\"accuracy\": 0.75, \"epoch\": 515}, {\"accuracy\": 0.75, \"epoch\": 516}, {\"accuracy\": 0.75, \"epoch\": 517}, {\"accuracy\": 0.75, \"epoch\": 518}, {\"accuracy\": 0.75, \"epoch\": 519}, {\"accuracy\": 0.75, \"epoch\": 520}, {\"accuracy\": 0.75, \"epoch\": 521}, {\"accuracy\": 0.75, \"epoch\": 522}, {\"accuracy\": 0.75, \"epoch\": 523}, {\"accuracy\": 0.75, \"epoch\": 524}, {\"accuracy\": 0.75, \"epoch\": 525}, {\"accuracy\": 0.75, \"epoch\": 526}, {\"accuracy\": 0.75, \"epoch\": 527}, {\"accuracy\": 0.75, \"epoch\": 528}, {\"accuracy\": 0.75, \"epoch\": 529}, {\"accuracy\": 0.75, \"epoch\": 530}, {\"accuracy\": 0.75, \"epoch\": 531}, {\"accuracy\": 0.75, \"epoch\": 532}, {\"accuracy\": 0.75, \"epoch\": 533}, {\"accuracy\": 0.75, \"epoch\": 534}, {\"accuracy\": 0.75, \"epoch\": 535}, {\"accuracy\": 0.75, \"epoch\": 536}, {\"accuracy\": 0.75, \"epoch\": 537}, {\"accuracy\": 0.75, \"epoch\": 538}, {\"accuracy\": 0.75, \"epoch\": 539}, {\"accuracy\": 0.75, \"epoch\": 540}, {\"accuracy\": 0.75, \"epoch\": 541}, {\"accuracy\": 0.75, \"epoch\": 542}, {\"accuracy\": 0.75, \"epoch\": 543}, {\"accuracy\": 0.75, \"epoch\": 544}, {\"accuracy\": 0.75, \"epoch\": 545}, {\"accuracy\": 0.75, \"epoch\": 546}, {\"accuracy\": 0.75, \"epoch\": 547}, {\"accuracy\": 0.75, \"epoch\": 548}, {\"accuracy\": 0.75, \"epoch\": 549}, {\"accuracy\": 0.75, \"epoch\": 550}, {\"accuracy\": 0.75, \"epoch\": 551}, {\"accuracy\": 0.75, \"epoch\": 552}, {\"accuracy\": 0.75, \"epoch\": 553}, {\"accuracy\": 0.75, \"epoch\": 554}, {\"accuracy\": 0.75, \"epoch\": 555}, {\"accuracy\": 0.75, \"epoch\": 556}, {\"accuracy\": 0.75, \"epoch\": 557}, {\"accuracy\": 0.75, \"epoch\": 558}, {\"accuracy\": 0.75, \"epoch\": 559}, {\"accuracy\": 0.75, \"epoch\": 560}, {\"accuracy\": 0.75, \"epoch\": 561}, {\"accuracy\": 0.75, \"epoch\": 562}, {\"accuracy\": 0.75, \"epoch\": 563}, {\"accuracy\": 0.75, \"epoch\": 564}, {\"accuracy\": 0.75, \"epoch\": 565}, {\"accuracy\": 0.75, \"epoch\": 566}, {\"accuracy\": 0.75, \"epoch\": 567}, {\"accuracy\": 0.75, \"epoch\": 568}, {\"accuracy\": 0.75, \"epoch\": 569}, {\"accuracy\": 0.75, \"epoch\": 570}, {\"accuracy\": 0.75, \"epoch\": 571}, {\"accuracy\": 0.75, \"epoch\": 572}, {\"accuracy\": 0.75, \"epoch\": 573}, {\"accuracy\": 0.75, \"epoch\": 574}, {\"accuracy\": 0.75, \"epoch\": 575}, {\"accuracy\": 0.75, \"epoch\": 576}, {\"accuracy\": 0.75, \"epoch\": 577}, {\"accuracy\": 0.75, \"epoch\": 578}, {\"accuracy\": 0.75, \"epoch\": 579}, {\"accuracy\": 0.75, \"epoch\": 580}, {\"accuracy\": 0.75, \"epoch\": 581}, {\"accuracy\": 0.75, \"epoch\": 582}, {\"accuracy\": 0.75, \"epoch\": 583}, {\"accuracy\": 0.75, \"epoch\": 584}, {\"accuracy\": 0.75, \"epoch\": 585}, {\"accuracy\": 0.75, \"epoch\": 586}, {\"accuracy\": 0.75, \"epoch\": 587}, {\"accuracy\": 0.75, \"epoch\": 588}, {\"accuracy\": 0.75, \"epoch\": 589}, {\"accuracy\": 0.75, \"epoch\": 590}, {\"accuracy\": 0.75, \"epoch\": 591}, {\"accuracy\": 0.75, \"epoch\": 592}, {\"accuracy\": 0.75, \"epoch\": 593}, {\"accuracy\": 0.75, \"epoch\": 594}, {\"accuracy\": 0.75, \"epoch\": 595}, {\"accuracy\": 0.75, \"epoch\": 596}, {\"accuracy\": 0.75, \"epoch\": 597}, {\"accuracy\": 0.75, \"epoch\": 598}, {\"accuracy\": 0.75, \"epoch\": 599}, {\"accuracy\": 0.75, \"epoch\": 600}, {\"accuracy\": 0.75, \"epoch\": 601}, {\"accuracy\": 0.75, \"epoch\": 602}, {\"accuracy\": 0.75, \"epoch\": 603}, {\"accuracy\": 0.75, \"epoch\": 604}, {\"accuracy\": 0.75, \"epoch\": 605}, {\"accuracy\": 0.75, \"epoch\": 606}, {\"accuracy\": 0.75, \"epoch\": 607}, {\"accuracy\": 0.75, \"epoch\": 608}, {\"accuracy\": 0.75, \"epoch\": 609}, {\"accuracy\": 0.75, \"epoch\": 610}, {\"accuracy\": 0.75, \"epoch\": 611}, {\"accuracy\": 0.75, \"epoch\": 612}, {\"accuracy\": 0.75, \"epoch\": 613}, {\"accuracy\": 0.75, \"epoch\": 614}, {\"accuracy\": 0.75, \"epoch\": 615}, {\"accuracy\": 0.75, \"epoch\": 616}, {\"accuracy\": 0.75, \"epoch\": 617}, {\"accuracy\": 0.75, \"epoch\": 618}, {\"accuracy\": 0.75, \"epoch\": 619}, {\"accuracy\": 0.75, \"epoch\": 620}, {\"accuracy\": 0.75, \"epoch\": 621}, {\"accuracy\": 0.75, \"epoch\": 622}, {\"accuracy\": 0.75, \"epoch\": 623}, {\"accuracy\": 0.75, \"epoch\": 624}, {\"accuracy\": 0.75, \"epoch\": 625}, {\"accuracy\": 0.75, \"epoch\": 626}, {\"accuracy\": 0.75, \"epoch\": 627}, {\"accuracy\": 0.75, \"epoch\": 628}, {\"accuracy\": 0.75, \"epoch\": 629}, {\"accuracy\": 0.75, \"epoch\": 630}, {\"accuracy\": 0.75, \"epoch\": 631}, {\"accuracy\": 0.75, \"epoch\": 632}, {\"accuracy\": 0.75, \"epoch\": 633}, {\"accuracy\": 0.75, \"epoch\": 634}, {\"accuracy\": 0.75, \"epoch\": 635}, {\"accuracy\": 0.75, \"epoch\": 636}, {\"accuracy\": 0.75, \"epoch\": 637}, {\"accuracy\": 0.75, \"epoch\": 638}, {\"accuracy\": 0.75, \"epoch\": 639}, {\"accuracy\": 0.75, \"epoch\": 640}, {\"accuracy\": 0.75, \"epoch\": 641}, {\"accuracy\": 0.75, \"epoch\": 642}, {\"accuracy\": 0.75, \"epoch\": 643}, {\"accuracy\": 0.75, \"epoch\": 644}, {\"accuracy\": 0.75, \"epoch\": 645}, {\"accuracy\": 0.75, \"epoch\": 646}, {\"accuracy\": 0.75, \"epoch\": 647}, {\"accuracy\": 0.75, \"epoch\": 648}, {\"accuracy\": 0.75, \"epoch\": 649}, {\"accuracy\": 0.75, \"epoch\": 650}, {\"accuracy\": 0.75, \"epoch\": 651}, {\"accuracy\": 0.75, \"epoch\": 652}, {\"accuracy\": 0.75, \"epoch\": 653}, {\"accuracy\": 0.75, \"epoch\": 654}, {\"accuracy\": 0.75, \"epoch\": 655}, {\"accuracy\": 0.75, \"epoch\": 656}, {\"accuracy\": 0.75, \"epoch\": 657}, {\"accuracy\": 0.75, \"epoch\": 658}, {\"accuracy\": 0.75, \"epoch\": 659}, {\"accuracy\": 0.75, \"epoch\": 660}, {\"accuracy\": 0.75, \"epoch\": 661}, {\"accuracy\": 0.75, \"epoch\": 662}, {\"accuracy\": 0.75, \"epoch\": 663}, {\"accuracy\": 0.75, \"epoch\": 664}, {\"accuracy\": 0.75, \"epoch\": 665}, {\"accuracy\": 0.75, \"epoch\": 666}, {\"accuracy\": 0.75, \"epoch\": 667}, {\"accuracy\": 0.75, \"epoch\": 668}, {\"accuracy\": 0.75, \"epoch\": 669}, {\"accuracy\": 0.75, \"epoch\": 670}, {\"accuracy\": 0.75, \"epoch\": 671}, {\"accuracy\": 0.75, \"epoch\": 672}, {\"accuracy\": 0.75, \"epoch\": 673}, {\"accuracy\": 0.75, \"epoch\": 674}, {\"accuracy\": 0.75, \"epoch\": 675}, {\"accuracy\": 0.75, \"epoch\": 676}, {\"accuracy\": 0.75, \"epoch\": 677}, {\"accuracy\": 0.75, \"epoch\": 678}, {\"accuracy\": 0.75, \"epoch\": 679}, {\"accuracy\": 0.75, \"epoch\": 680}, {\"accuracy\": 0.75, \"epoch\": 681}, {\"accuracy\": 0.75, \"epoch\": 682}, {\"accuracy\": 0.75, \"epoch\": 683}, {\"accuracy\": 0.75, \"epoch\": 684}, {\"accuracy\": 0.75, \"epoch\": 685}, {\"accuracy\": 0.75, \"epoch\": 686}, {\"accuracy\": 0.75, \"epoch\": 687}, {\"accuracy\": 0.75, \"epoch\": 688}, {\"accuracy\": 0.75, \"epoch\": 689}, {\"accuracy\": 0.75, \"epoch\": 690}, {\"accuracy\": 0.75, \"epoch\": 691}, {\"accuracy\": 0.75, \"epoch\": 692}, {\"accuracy\": 0.75, \"epoch\": 693}, {\"accuracy\": 0.75, \"epoch\": 694}, {\"accuracy\": 0.75, \"epoch\": 695}, {\"accuracy\": 0.75, \"epoch\": 696}, {\"accuracy\": 0.75, \"epoch\": 697}, {\"accuracy\": 0.75, \"epoch\": 698}, {\"accuracy\": 0.75, \"epoch\": 699}, {\"accuracy\": 0.75, \"epoch\": 700}, {\"accuracy\": 0.75, \"epoch\": 701}, {\"accuracy\": 0.75, \"epoch\": 702}, {\"accuracy\": 0.75, \"epoch\": 703}, {\"accuracy\": 0.75, \"epoch\": 704}, {\"accuracy\": 0.75, \"epoch\": 705}, {\"accuracy\": 0.75, \"epoch\": 706}, {\"accuracy\": 0.75, \"epoch\": 707}, {\"accuracy\": 0.75, \"epoch\": 708}, {\"accuracy\": 0.75, \"epoch\": 709}, {\"accuracy\": 0.75, \"epoch\": 710}, {\"accuracy\": 0.75, \"epoch\": 711}, {\"accuracy\": 0.75, \"epoch\": 712}, {\"accuracy\": 0.75, \"epoch\": 713}, {\"accuracy\": 0.75, \"epoch\": 714}, {\"accuracy\": 0.75, \"epoch\": 715}, {\"accuracy\": 0.75, \"epoch\": 716}, {\"accuracy\": 0.75, \"epoch\": 717}, {\"accuracy\": 0.75, \"epoch\": 718}, {\"accuracy\": 0.75, \"epoch\": 719}, {\"accuracy\": 0.75, \"epoch\": 720}, {\"accuracy\": 0.75, \"epoch\": 721}, {\"accuracy\": 0.75, \"epoch\": 722}, {\"accuracy\": 0.75, \"epoch\": 723}, {\"accuracy\": 0.75, \"epoch\": 724}, {\"accuracy\": 0.75, \"epoch\": 725}, {\"accuracy\": 0.75, \"epoch\": 726}, {\"accuracy\": 0.75, \"epoch\": 727}, {\"accuracy\": 0.75, \"epoch\": 728}, {\"accuracy\": 0.75, \"epoch\": 729}, {\"accuracy\": 0.75, \"epoch\": 730}, {\"accuracy\": 0.75, \"epoch\": 731}, {\"accuracy\": 0.75, \"epoch\": 732}, {\"accuracy\": 0.75, \"epoch\": 733}, {\"accuracy\": 0.75, \"epoch\": 734}, {\"accuracy\": 0.75, \"epoch\": 735}, {\"accuracy\": 0.75, \"epoch\": 736}, {\"accuracy\": 0.75, \"epoch\": 737}, {\"accuracy\": 0.75, \"epoch\": 738}, {\"accuracy\": 0.75, \"epoch\": 739}, {\"accuracy\": 0.75, \"epoch\": 740}, {\"accuracy\": 0.75, \"epoch\": 741}, {\"accuracy\": 0.75, \"epoch\": 742}, {\"accuracy\": 0.75, \"epoch\": 743}, {\"accuracy\": 0.75, \"epoch\": 744}, {\"accuracy\": 0.75, \"epoch\": 745}, {\"accuracy\": 0.75, \"epoch\": 746}, {\"accuracy\": 0.75, \"epoch\": 747}, {\"accuracy\": 0.75, \"epoch\": 748}, {\"accuracy\": 0.75, \"epoch\": 749}, {\"accuracy\": 0.75, \"epoch\": 750}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Relation of different GDs in a single dataset represented with a graph"
      ],
      "metadata": {
        "id": "30skMh-U8zMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING OPTIMIZATION ALGO WITH EARLY STOP AT 100% ACCURACY\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# XOR dataset\n",
        "y = np.array([[0, 1, 1, 0]]).T\n",
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]]).T\n",
        "\n",
        "\n",
        "# Custom callback to stop at 100% accuracy\n",
        "class StopAtAccuracy(Callback):\n",
        "    def __init__(self, target_accuracy=1.0):\n",
        "        super(StopAtAccuracy, self).__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        acc = logs.get(\"binary_accuracy\")\n",
        "        if acc >= self.target_accuracy:\n",
        "            print(f\"\\nReached {self.target_accuracy*100}% accuracy. Stopping training.\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "\n",
        "# Build model\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X, y,\n",
        "    epochs=10000,   # Large upper limit\n",
        "    verbose=0,\n",
        "    callbacks=[StopAtAccuracy(target_accuracy=1.0)]\n",
        ")\n",
        "\n",
        "# ----------------------\n",
        "# Plot Loss Graph\n",
        "# ----------------------\n",
        "df_loss = pd.DataFrame({\n",
        "    \"Loss\": history.history['loss'],\n",
        "    \"Epoch\": np.arange(1, len(history.history['loss']) + 1)\n",
        "})\n",
        "\n",
        "loss_chart = alt.Chart(df_loss).mark_line().encode(\n",
        "    x='Epoch',\n",
        "    y='Loss'\n",
        ").properties(title='Loss vs Epochs')\n",
        "\n",
        "loss_chart\n",
        "\n",
        "# ----------------------\n",
        "# Plot Accuracy Graph\n",
        "# ----------------------\n",
        "df_acc = pd.DataFrame({\n",
        "    \"Accuracy (%)\": np.array(history.history['binary_accuracy']) * 100,\n",
        "    \"Epoch\": np.arange(1, len(history.history['binary_accuracy']) + 1)\n",
        "})\n",
        "\n",
        "accuracy_chart = alt.Chart(df_acc).mark_line(color='green').encode(\n",
        "    x='Epoch',\n",
        "    y='Accuracy (%)'\n",
        ").properties(title='Accuracy vs Epochs')\n",
        "\n",
        "accuracy_chart\n",
        "\n",
        "# ----------------------\n",
        "# Final Predictions\n",
        "# ----------------------\n",
        "y_pred = model.predict(X).round()\n",
        "num_correct_predictions = (y_pred == y).sum()\n",
        "accuracy = (num_correct_predictions / y.shape[0]) * 100\n",
        "\n",
        "print('\\nMulti-layer perceptron accuracy: %.2f%%' % accuracy)\n",
        "print(\"Training stopped at epoch:\", len(history.history['loss']))\n",
        "\n",
        "# ----------------------\n",
        "# Display Weights and Biases\n",
        "# ----------------------\n",
        "print(\"\\nModel Weights and Biases at 100% Accuracy:\\n\")\n",
        "\n",
        "for i, layer in enumerate(model.layers):\n",
        "    weights, biases = layer.get_weights()\n",
        "    print(f\"Layer {i+1}\")\n",
        "    print(\"Weights:\\n\", weights)\n",
        "    print(\"Biases:\\n\", biases)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX_1hv8XFRKF",
        "outputId": "bec8ad7e-0c23-452d-8f89-09d806a1bd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reached 100.0% accuracy. Stopping training.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\n",
            "Multi-layer perceptron accuracy: 100.00%\n",
            "Training stopped at epoch: 388\n",
            "\n",
            "Model Weights and Biases at 100% Accuracy:\n",
            "\n",
            "Layer 1\n",
            "Weights:\n",
            " [[ 0.23873307  0.64787424 -0.89255667  0.12493826 -0.8363507   0.12835038\n",
            "   0.8925751  -0.21722013  0.5999374   0.10851157 -0.03392179 -0.02077759\n",
            "   0.44906995  0.09210632 -0.6444206   0.53710264]\n",
            " [-0.43901122 -0.26867968  0.69346905 -0.11409435 -0.8573     -0.25235334\n",
            "  -0.71707433 -0.24068536 -0.8371977  -0.23968817  0.05541928 -0.30530012\n",
            "  -0.56102157  0.29870296  0.9255541   0.3146206 ]]\n",
            "Biases:\n",
            " [-0.15793419  0.15434477 -0.42849454 -0.02726281 -0.37039515 -0.04545999\n",
            "  0.43708163  0.18605322 -0.37157533  0.0079011   0.05850601  0.09439908\n",
            "  0.2981084  -0.14547458  0.37390062  0.19253711]\n",
            "--------------------------------------------------\n",
            "Layer 2\n",
            "Weights:\n",
            " [[ 0.31078988]\n",
            " [-0.17931108]\n",
            " [ 0.4578649 ]\n",
            " [ 0.1242798 ]\n",
            " [-0.5039844 ]\n",
            " [ 0.42880252]\n",
            " [-0.08898497]\n",
            " [ 0.3370977 ]\n",
            " [ 0.2642071 ]\n",
            " [-0.03364104]\n",
            " [ 0.14102624]\n",
            " [ 0.1665914 ]\n",
            " [-0.58610845]\n",
            " [-0.49516296]\n",
            " [-0.51104766]\n",
            " [ 0.22842859]]\n",
            "Biases:\n",
            " [0.0491506]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different Gradient Descent Optimizers"
      ],
      "metadata": {
        "id": "G8dnZB0tICfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import (\n",
        "    SGD, RMSprop, Adam,\n",
        "    Adagrad, Adadelta, Adamax, Nadam, Ftrl\n",
        ")\n",
        "\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data (XOR problem)\n",
        "y = np.array([[0, 1, 1, 0]]).T\n",
        "X = np.array([[0, 0, 1, 1],\n",
        "              [0, 1, 0, 1]]).T\n",
        "\n",
        "# List of optimizers to compare\n",
        "optimizers = {\n",
        "    # Basic SGD\n",
        "    \"SGD\": SGD(learning_rate=0.1),\n",
        "\n",
        "    # SGD with Momentum\n",
        "    \"SGD_Momentum\": SGD(learning_rate=0.1, momentum=0.9),\n",
        "\n",
        "    # Nesterov Momentum\n",
        "    \"SGD_Nesterov\": SGD(learning_rate=0.1, momentum=0.9, nesterov=True),\n",
        "\n",
        "    # Adaptive methods\n",
        "    \"Adagrad\": Adagrad(learning_rate=0.1),\n",
        "    \"Adadelta\": Adadelta(learning_rate=1.0),\n",
        "    \"RMSprop\": RMSprop(learning_rate=0.01),\n",
        "\n",
        "    # Adam family\n",
        "    \"Adam\": Adam(learning_rate=0.01),\n",
        "    \"Adamax\": Adamax(learning_rate=0.01),\n",
        "    \"Nadam\": Nadam(learning_rate=0.01),\n",
        "\n",
        "    # FTRL (mainly used for sparse models, but can test)\n",
        "    \"Ftrl\": Ftrl(learning_rate=0.1)\n",
        "}\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "# Train model with each optimizer\n",
        "for name, opt in optimizers.items():\n",
        "\n",
        "    # Recreate model each time\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=2, activation='sigmoid'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['binary_accuracy'])\n",
        "\n",
        "    history = model.fit(X, y, epochs=300, verbose=0)\n",
        "\n",
        "    # Store accuracy history\n",
        "    for epoch, acc in enumerate(history.history['binary_accuracy']):\n",
        "        results.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"accuracy\": acc * 100,\n",
        "            \"optimizer\": name\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Plot comparison graph\n",
        "chart = alt.Chart(df).mark_line().encode(\n",
        "    x=alt.X('epoch', title='Epoch'),\n",
        "    y=alt.Y('accuracy', title='Accuracy (%)', scale=alt.Scale(domain=[0, 100])),\n",
        ").properties(\n",
        "    width=200,\n",
        "    height=150\n",
        ").facet(\n",
        "    facet='optimizer',\n",
        "    columns=3\n",
        ").properties(\n",
        "    title='Accuracy Comparison of Optimizers (XOR)'\n",
        ")\n",
        "\n",
        "chart\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "Ia7k3oWZHeHV",
        "outputId": "ba3d2cea-d788-4860-934f-842651c39250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-2d09e292a95545178cd093f1e35467ed.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-2d09e292a95545178cd093f1e35467ed.vega-embed details,\n",
              "  #altair-viz-2d09e292a95545178cd093f1e35467ed.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-2d09e292a95545178cd093f1e35467ed\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-2d09e292a95545178cd093f1e35467ed\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-2d09e292a95545178cd093f1e35467ed\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0445fb8fc4ddbcdb97d489ecb5f08a40\"}, \"facet\": {\"field\": \"optimizer\", \"type\": \"nominal\"}, \"spec\": {\"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"epoch\", \"title\": \"Epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Accuracy (%)\", \"type\": \"quantitative\"}}, \"height\": 150, \"width\": 200}, \"columns\": 3, \"title\": \"Accuracy Comparison of Optimizers (XOR)\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-0445fb8fc4ddbcdb97d489ecb5f08a40\": [{\"epoch\": 0, \"accuracy\": 25.0, \"optimizer\": \"SGD\"}, {\"epoch\": 1, \"accuracy\": 25.0, \"optimizer\": \"SGD\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 42, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 43, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 44, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 45, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 47, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 48, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 49, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 50, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 51, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 52, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 53, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 54, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 55, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 57, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 63, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 64, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 71, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 80, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 81, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 82, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 83, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 101, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 102, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 103, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 104, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 105, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 106, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 107, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 108, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 109, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 110, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 111, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 112, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 113, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 114, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 115, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 116, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 117, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 118, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 119, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 120, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 121, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 122, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 123, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 124, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 125, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 126, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 127, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 128, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 129, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 130, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 131, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 132, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 133, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 134, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 135, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 136, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 137, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 138, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 139, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 140, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 141, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 142, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 143, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 144, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 145, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 146, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 147, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 148, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 149, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 150, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 151, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 152, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 153, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 154, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 155, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 156, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 157, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 158, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 159, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 160, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 161, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 162, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 163, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 164, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 165, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 166, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 167, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 168, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 169, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 170, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 171, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 172, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 173, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 174, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 175, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 176, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 177, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 178, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 179, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 180, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 181, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 182, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 183, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 184, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 185, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 186, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 187, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 188, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 189, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 190, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 191, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 192, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 193, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 194, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 195, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 196, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 197, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 198, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 199, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 200, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 201, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 202, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 203, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 204, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 205, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 206, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 207, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 208, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 209, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 210, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 211, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 212, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 213, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 214, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 215, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 216, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 217, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 218, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 219, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 220, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 221, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 222, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 223, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 224, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 225, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 226, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 227, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 228, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 229, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 230, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 231, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 232, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 233, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 234, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 235, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 236, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 237, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 238, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 239, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 240, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 241, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 242, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 243, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 244, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 245, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 246, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 247, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 248, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 249, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 250, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 251, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 252, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 253, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 254, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 255, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 256, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 257, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 258, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 259, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 260, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 261, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 262, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 263, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 264, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 265, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 266, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 267, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 268, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 269, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 270, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 271, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 272, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 273, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 274, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 275, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 276, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 277, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 278, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 279, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 280, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 281, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 282, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 283, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 284, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 285, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 286, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 287, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 288, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 289, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 290, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 291, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 292, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 293, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 294, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 295, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 296, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 297, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 298, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 299, \"accuracy\": 50.0, \"optimizer\": \"SGD\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 6, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 8, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 18, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 21, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 22, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 29, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 30, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 31, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 35, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 36, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 37, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 38, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 39, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 40, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 41, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 42, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 43, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 44, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 45, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 47, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 48, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 49, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 50, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 51, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 52, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 53, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 54, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 55, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 56, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 57, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 58, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 59, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 60, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 63, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 64, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 65, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 66, \"accuracy\": 25.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 68, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 69, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 70, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 71, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 72, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 73, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 74, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 75, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 76, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 77, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 78, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 79, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 80, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 81, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 82, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 83, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 84, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 85, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 86, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 101, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 102, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 103, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 104, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 105, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 106, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 107, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 108, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 109, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 110, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 111, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 112, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 113, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 114, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 115, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 116, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 117, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 118, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 119, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 120, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 121, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 122, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 123, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 124, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 125, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 126, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 127, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 128, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 129, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 130, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 131, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 132, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 133, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 134, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 135, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 136, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 137, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 138, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 139, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 140, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 141, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 142, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 143, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 144, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 145, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 146, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 147, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 148, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 149, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 150, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 151, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 152, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 153, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 154, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 155, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 156, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 157, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 158, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 159, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 160, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 161, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 162, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 163, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 164, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 165, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 166, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 167, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 168, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 169, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 170, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 171, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 172, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 173, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 174, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 175, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 176, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 177, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 178, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 179, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 180, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 181, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 182, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 183, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 184, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 185, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 186, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 187, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 188, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 189, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 190, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 191, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 192, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 193, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 194, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 195, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 196, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 197, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 198, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 199, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 200, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 201, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 202, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 203, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 204, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 205, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 206, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 207, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 208, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 209, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 210, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 211, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 212, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 213, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 214, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 215, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 216, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 217, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 218, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 219, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 220, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 221, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 222, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 223, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 224, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 225, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 226, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 227, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 228, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 229, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 230, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 231, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 232, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 233, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 234, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 235, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 236, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 237, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 238, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 239, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 240, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 241, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 242, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 243, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 244, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 245, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 246, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 247, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 248, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 249, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 250, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 251, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 252, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 253, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 254, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 255, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 256, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 257, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 258, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 259, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 260, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 261, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 262, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 263, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 264, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 265, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 266, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 267, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 268, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 269, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 270, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 271, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 272, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 273, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 274, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 275, \"accuracy\": 50.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 276, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 277, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 278, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 279, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 280, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 281, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 282, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 283, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 284, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 285, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 286, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 287, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 288, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 289, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 290, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 291, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 292, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 293, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 294, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 295, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 296, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 297, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 298, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 299, \"accuracy\": 75.0, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 7, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 19, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 20, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 21, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 22, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 29, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 30, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 31, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 32, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 33, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 34, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 35, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 36, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 37, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 38, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 39, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 40, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 41, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 42, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 43, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 44, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 45, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 47, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 48, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 49, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 50, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 51, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 52, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 53, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 54, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 55, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 56, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 57, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 61, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 62, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 63, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 64, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 65, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 66, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 67, \"accuracy\": 25.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 71, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 80, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 81, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 82, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 83, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 101, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 102, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 103, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 104, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 105, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 106, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 107, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 108, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 109, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 110, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 111, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 112, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 113, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 114, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 115, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 116, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 117, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 118, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 119, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 120, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 121, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 122, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 123, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 124, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 125, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 126, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 127, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 128, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 129, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 130, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 131, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 132, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 133, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 134, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 135, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 136, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 137, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 138, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 139, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 140, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 141, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 142, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 143, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 144, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 145, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 146, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 147, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 148, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 149, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 150, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 151, \"accuracy\": 75.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 152, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 153, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 154, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 155, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 156, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 157, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 158, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 159, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 160, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 161, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 162, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 163, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 164, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 165, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 166, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 167, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 168, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 169, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 170, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 171, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 172, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 173, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 174, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 175, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 176, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 177, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 178, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 179, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 180, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 181, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 182, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 183, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 184, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 185, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 186, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 187, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 188, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 189, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 190, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 191, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 192, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 193, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 194, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 195, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 196, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 197, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 198, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 199, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 200, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 201, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 202, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 203, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 204, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 205, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 206, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 207, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 208, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 209, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 210, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 211, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 212, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 213, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 214, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 215, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 216, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 217, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 218, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 219, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 220, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 221, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 222, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 223, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 224, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 225, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 226, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 227, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 228, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 229, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 230, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 231, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 232, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 233, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 234, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 235, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 236, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 237, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 238, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 239, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 240, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 241, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 242, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 243, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 244, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 245, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 246, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 247, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 248, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 249, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 250, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 251, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 252, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 253, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 254, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 255, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 256, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 257, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 258, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 259, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 260, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 261, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 262, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 263, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 264, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 265, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 266, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 267, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 268, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 269, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 270, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 271, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 272, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 273, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 274, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 275, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 276, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 277, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 278, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 279, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 280, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 281, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 282, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 283, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 284, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 285, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 286, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 287, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 288, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 289, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 290, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 291, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 292, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 293, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 294, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 295, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 296, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 297, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 298, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 299, \"accuracy\": 50.0, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 1, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 2, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 3, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 4, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 5, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 6, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 7, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 8, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 9, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 10, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 11, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 12, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 13, \"accuracy\": 75.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 42, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 43, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 44, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 45, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 47, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 48, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 49, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 50, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 51, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 52, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 53, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 54, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 55, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 57, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 63, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 64, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 71, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 80, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 81, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 82, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 83, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 101, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 102, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 103, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 104, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 105, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 106, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 107, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 108, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 109, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 110, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 111, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 112, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 113, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 114, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 115, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 116, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 117, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 118, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 119, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 120, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 121, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 122, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 123, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 124, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 125, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 126, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 127, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 128, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 129, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 130, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 131, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 132, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 133, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 134, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 135, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 136, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 137, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 138, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 139, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 140, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 141, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 142, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 143, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 144, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 145, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 146, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 147, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 148, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 149, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 150, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 151, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 152, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 153, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 154, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 155, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 156, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 157, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 158, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 159, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 160, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 161, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 162, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 163, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 164, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 165, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 166, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 167, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 168, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 169, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 170, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 171, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 172, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 173, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 174, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 175, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 176, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 177, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 178, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 179, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 180, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 181, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 182, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 183, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 184, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 185, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 186, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 187, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 188, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 189, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 190, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 191, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 192, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 193, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 194, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 195, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 196, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 197, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 198, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 199, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 200, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 201, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 202, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 203, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 204, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 205, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 206, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 207, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 208, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 209, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 210, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 211, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 212, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 213, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 214, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 215, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 216, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 217, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 218, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 219, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 220, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 221, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 222, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 223, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 224, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 225, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 226, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 227, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 228, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 229, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 230, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 231, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 232, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 233, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 234, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 235, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 236, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 237, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 238, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 239, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 240, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 241, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 242, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 243, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 244, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 245, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 246, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 247, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 248, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 249, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 250, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 251, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 252, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 253, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 254, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 255, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 256, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 257, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 258, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 259, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 260, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 261, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 262, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 263, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 264, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 265, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 266, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 267, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 268, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 269, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 270, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 271, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 272, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 273, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 274, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 275, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 276, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 277, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 278, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 279, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 280, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 281, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 282, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 283, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 284, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 285, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 286, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 287, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 288, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 289, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 290, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 291, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 292, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 293, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 294, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 295, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 296, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 297, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 298, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 299, \"accuracy\": 50.0, \"optimizer\": \"Adagrad\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 42, \"accuracy\": 75.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 43, \"accuracy\": 75.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 44, \"accuracy\": 75.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 45, \"accuracy\": 75.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 46, \"accuracy\": 75.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 47, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 48, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 49, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 50, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 51, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 52, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 53, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 54, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 55, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 57, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 63, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 64, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 71, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 80, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 81, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 82, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 83, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 101, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 102, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 103, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 104, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 105, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 106, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 107, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 108, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 109, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 110, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 111, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 112, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 113, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 114, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 115, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 116, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 117, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 118, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 119, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 120, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 121, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 122, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 123, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 124, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 125, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 126, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 127, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 128, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 129, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 130, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 131, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 132, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 133, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 134, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 135, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 136, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 137, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 138, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 139, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 140, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 141, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 142, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 143, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 144, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 145, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 146, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 147, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 148, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 149, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 150, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 151, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 152, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 153, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 154, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 155, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 156, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 157, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 158, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 159, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 160, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 161, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 162, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 163, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 164, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 165, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 166, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 167, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 168, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 169, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 170, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 171, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 172, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 173, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 174, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 175, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 176, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 177, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 178, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 179, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 180, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 181, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 182, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 183, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 184, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 185, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 186, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 187, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 188, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 189, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 190, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 191, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 192, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 193, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 194, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 195, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 196, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 197, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 198, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 199, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 200, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 201, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 202, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 203, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 204, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 205, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 206, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 207, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 208, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 209, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 210, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 211, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 212, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 213, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 214, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 215, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 216, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 217, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 218, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 219, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 220, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 221, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 222, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 223, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 224, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 225, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 226, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 227, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 228, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 229, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 230, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 231, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 232, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 233, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 234, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 235, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 236, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 237, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 238, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 239, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 240, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 241, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 242, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 243, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 244, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 245, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 246, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 247, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 248, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 249, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 250, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 251, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 252, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 253, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 254, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 255, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 256, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 257, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 258, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 259, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 260, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 261, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 262, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 263, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 264, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 265, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 266, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 267, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 268, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 269, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 270, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 271, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 272, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 273, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 274, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 275, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 276, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 277, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 278, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 279, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 280, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 281, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 282, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 283, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 284, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 285, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 286, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 287, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 288, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 289, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 290, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 291, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 292, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 293, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 294, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 295, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 296, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 297, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 298, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 299, \"accuracy\": 50.0, \"optimizer\": \"Adadelta\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 3, \"accuracy\": 25.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 4, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 14, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 15, \"accuracy\": 25.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 42, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 43, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 44, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 45, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 47, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 48, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 49, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 50, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 51, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 52, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 53, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 54, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 55, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 57, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 63, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 64, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 67, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 69, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 71, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 73, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 74, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 75, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 76, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 77, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 78, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 79, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 80, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 81, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 82, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 83, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 84, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 85, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 86, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 87, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 88, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 89, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 90, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 91, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 92, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 93, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 94, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 95, \"accuracy\": 75.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 96, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 97, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 98, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 99, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 100, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 101, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 102, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 103, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 104, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 105, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 106, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 107, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 108, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 109, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 110, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 111, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 112, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 113, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 114, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 115, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 116, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 117, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 118, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 119, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 120, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 121, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 122, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 123, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 124, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 125, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 126, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 127, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 128, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 129, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 130, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 131, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 132, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 133, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 134, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 135, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 136, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 137, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 138, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 139, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 140, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 141, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 142, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 143, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 144, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 145, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 146, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 147, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 148, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 149, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 150, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 151, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 152, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 153, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 154, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 155, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 156, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 157, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 158, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 159, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 160, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 161, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 162, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 163, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 164, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 165, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 166, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 167, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 168, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 169, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 170, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 171, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 172, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 173, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 174, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 175, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 176, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 177, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 178, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 179, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 180, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 181, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 182, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 183, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 184, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 185, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 186, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 187, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 188, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 189, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 190, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 191, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 192, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 193, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 194, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 195, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 196, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 197, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 198, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 199, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 200, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 201, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 202, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 203, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 204, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 205, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 206, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 207, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 208, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 209, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 210, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 211, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 212, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 213, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 214, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 215, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 216, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 217, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 218, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 219, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 220, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 221, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 222, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 223, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 224, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 225, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 226, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 227, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 228, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 229, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 230, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 231, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 232, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 233, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 234, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 235, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 236, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 237, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 238, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 239, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 240, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 241, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 242, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 243, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 244, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 245, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 246, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 247, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 248, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 249, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 250, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 251, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 252, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 253, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 254, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 255, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 256, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 257, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 258, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 259, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 260, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 261, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 262, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 263, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 264, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 265, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 266, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 267, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 268, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 269, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 270, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 271, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 272, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 273, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 274, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 275, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 276, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 277, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 278, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 279, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 280, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 281, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 282, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 283, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 284, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 285, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 286, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 287, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 288, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 289, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 290, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 291, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 292, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 293, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 294, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 295, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 296, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 297, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 298, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 299, \"accuracy\": 100.0, \"optimizer\": \"RMSprop\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 42, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 43, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 44, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 45, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 47, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 48, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 49, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 50, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 51, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 52, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 53, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 54, \"accuracy\": 25.0, \"optimizer\": \"Adam\"}, {\"epoch\": 55, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 57, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 58, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 59, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 60, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 61, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 62, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 63, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 64, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 70, \"accuracy\": 25.0, \"optimizer\": \"Adam\"}, {\"epoch\": 71, \"accuracy\": 25.0, \"optimizer\": \"Adam\"}, {\"epoch\": 72, \"accuracy\": 25.0, \"optimizer\": \"Adam\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 80, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 81, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 82, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 83, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"Adam\"}, {\"epoch\": 99, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 100, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 101, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 102, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 103, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 104, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 105, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 106, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 107, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 108, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 109, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 110, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 111, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 112, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 113, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 114, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 115, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 116, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 117, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 118, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 119, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 120, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 121, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 122, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 123, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 124, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 125, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 126, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 127, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 128, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 129, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 130, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 131, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 132, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 133, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 134, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 135, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 136, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 137, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 138, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 139, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 140, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 141, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 142, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 143, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 144, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 145, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 146, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 147, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 148, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 149, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 150, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 151, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 152, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 153, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 154, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 155, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 156, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 157, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 158, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 159, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 160, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 161, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 162, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 163, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 164, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 165, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 166, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 167, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 168, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 169, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 170, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 171, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 172, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 173, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 174, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 175, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 176, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 177, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 178, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 179, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 180, \"accuracy\": 75.0, \"optimizer\": \"Adam\"}, {\"epoch\": 181, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 182, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 183, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 184, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 185, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 186, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 187, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 188, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 189, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 190, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 191, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 192, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 193, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 194, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 195, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 196, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 197, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 198, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 199, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 200, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 201, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 202, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 203, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 204, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 205, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 206, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 207, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 208, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 209, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 210, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 211, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 212, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 213, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 214, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 215, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 216, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 217, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 218, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 219, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 220, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 221, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 222, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 223, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 224, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 225, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 226, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 227, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 228, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 229, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 230, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 231, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 232, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 233, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 234, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 235, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 236, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 237, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 238, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 239, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 240, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 241, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 242, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 243, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 244, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 245, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 246, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 247, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 248, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 249, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 250, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 251, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 252, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 253, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 254, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 255, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 256, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 257, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 258, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 259, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 260, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 261, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 262, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 263, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 264, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 265, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 266, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 267, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 268, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 269, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 270, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 271, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 272, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 273, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 274, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 275, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 276, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 277, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 278, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 279, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 280, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 281, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 282, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 283, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 284, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 285, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 286, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 287, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 288, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 289, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 290, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 291, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 292, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 293, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 294, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 295, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 296, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 297, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 298, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 299, \"accuracy\": 100.0, \"optimizer\": \"Adam\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 5, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 6, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 7, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 10, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 11, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 12, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 13, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 20, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 21, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 22, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 23, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 24, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 25, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 26, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 27, \"accuracy\": 25.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 42, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 43, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 44, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 45, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 46, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 47, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 48, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 49, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 50, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 51, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 52, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 53, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 54, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 55, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 57, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 63, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 64, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 71, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 80, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 81, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 82, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 83, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 101, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 102, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 103, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 104, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 105, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 106, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 107, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 108, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 109, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 110, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 111, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 112, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 113, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 114, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 115, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 116, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 117, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 118, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 119, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 120, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 121, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 122, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 123, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 124, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 125, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 126, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 127, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 128, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 129, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 130, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 131, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 132, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 133, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 134, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 135, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 136, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 137, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 138, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 139, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 140, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 141, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 142, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 143, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 144, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 145, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 146, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 147, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 148, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 149, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 150, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 151, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 152, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 153, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 154, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 155, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 156, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 157, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 158, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 159, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 160, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 161, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 162, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 163, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 164, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 165, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 166, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 167, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 168, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 169, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 170, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 171, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 172, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 173, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 174, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 175, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 176, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 177, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 178, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 179, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 180, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 181, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 182, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 183, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 184, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 185, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 186, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 187, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 188, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 189, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 190, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 191, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 192, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 193, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 194, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 195, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 196, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 197, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 198, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 199, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 200, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 201, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 202, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 203, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 204, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 205, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 206, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 207, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 208, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 209, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 210, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 211, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 212, \"accuracy\": 75.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 213, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 214, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 215, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 216, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 217, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 218, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 219, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 220, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 221, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 222, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 223, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 224, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 225, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 226, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 227, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 228, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 229, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 230, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 231, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 232, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 233, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 234, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 235, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 236, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 237, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 238, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 239, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 240, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 241, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 242, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 243, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 244, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 245, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 246, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 247, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 248, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 249, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 250, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 251, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 252, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 253, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 254, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 255, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 256, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 257, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 258, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 259, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 260, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 261, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 262, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 263, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 264, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 265, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 266, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 267, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 268, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 269, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 270, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 271, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 272, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 273, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 274, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 275, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 276, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 277, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 278, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 279, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 280, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 281, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 282, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 283, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 284, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 285, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 286, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 287, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 288, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 289, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 290, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 291, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 292, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 293, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 294, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 295, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 296, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 297, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 298, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 299, \"accuracy\": 100.0, \"optimizer\": \"Adamax\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 26, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 27, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 28, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 29, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 30, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 31, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 32, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 33, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 34, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 35, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 36, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 37, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 38, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 39, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 40, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 41, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 42, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 43, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 44, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 45, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 46, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 47, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 48, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 49, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 50, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 51, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 52, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 53, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 54, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 55, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 56, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 57, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 58, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 59, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 60, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 61, \"accuracy\": 75.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 62, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 63, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 64, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 65, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 66, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 67, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 68, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 69, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 70, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 71, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 72, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 73, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 74, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 75, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 76, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 77, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 78, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 79, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 80, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 81, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 82, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 83, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 84, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 85, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 86, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 87, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 88, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 89, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 90, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 91, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 92, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 93, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 94, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 95, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 96, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 97, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 98, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 99, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 100, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 101, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 102, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 103, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 104, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 105, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 106, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 107, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 108, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 109, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 110, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 111, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 112, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 113, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 114, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 115, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 116, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 117, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 118, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 119, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 120, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 121, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 122, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 123, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 124, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 125, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 126, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 127, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 128, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 129, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 130, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 131, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 132, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 133, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 134, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 135, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 136, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 137, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 138, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 139, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 140, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 141, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 142, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 143, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 144, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 145, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 146, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 147, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 148, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 149, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 150, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 151, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 152, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 153, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 154, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 155, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 156, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 157, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 158, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 159, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 160, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 161, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 162, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 163, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 164, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 165, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 166, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 167, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 168, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 169, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 170, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 171, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 172, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 173, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 174, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 175, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 176, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 177, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 178, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 179, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 180, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 181, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 182, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 183, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 184, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 185, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 186, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 187, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 188, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 189, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 190, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 191, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 192, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 193, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 194, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 195, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 196, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 197, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 198, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 199, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 200, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 201, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 202, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 203, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 204, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 205, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 206, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 207, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 208, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 209, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 210, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 211, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 212, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 213, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 214, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 215, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 216, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 217, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 218, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 219, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 220, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 221, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 222, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 223, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 224, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 225, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 226, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 227, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 228, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 229, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 230, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 231, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 232, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 233, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 234, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 235, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 236, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 237, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 238, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 239, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 240, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 241, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 242, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 243, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 244, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 245, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 246, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 247, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 248, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 249, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 250, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 251, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 252, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 253, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 254, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 255, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 256, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 257, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 258, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 259, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 260, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 261, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 262, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 263, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 264, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 265, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 266, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 267, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 268, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 269, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 270, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 271, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 272, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 273, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 274, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 275, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 276, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 277, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 278, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 279, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 280, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 281, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 282, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 283, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 284, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 285, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 286, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 287, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 288, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 289, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 290, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 291, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 292, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 293, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 294, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 295, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 296, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 297, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 298, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 299, \"accuracy\": 100.0, \"optimizer\": \"Nadam\"}, {\"epoch\": 0, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 1, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 2, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 3, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 4, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 5, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 6, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 7, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 8, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 9, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 10, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 11, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 12, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 13, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 14, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 15, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 16, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 17, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 18, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 19, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 20, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 21, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 22, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 23, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 24, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 25, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 26, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 27, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 28, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 29, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 30, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 31, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 32, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 33, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 34, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 35, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 36, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 37, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 38, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 39, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 40, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 41, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 42, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 43, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 44, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 45, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 46, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 47, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 48, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 49, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 50, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 51, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 52, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 53, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 54, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 55, \"accuracy\": 75.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 56, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 57, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 58, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 59, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 60, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 61, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 62, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 63, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 64, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 65, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 66, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 67, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 68, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 69, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 70, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 71, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 72, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 73, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 74, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 75, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 76, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 77, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 78, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 79, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 80, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 81, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 82, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 83, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 84, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 85, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 86, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 87, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 88, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 89, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 90, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 91, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 92, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 93, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 94, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 95, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 96, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 97, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 98, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 99, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 100, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 101, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 102, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 103, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 104, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 105, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 106, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 107, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 108, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 109, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 110, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 111, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 112, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 113, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 114, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 115, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 116, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 117, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 118, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 119, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 120, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 121, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 122, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 123, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 124, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 125, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 126, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 127, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 128, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 129, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 130, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 131, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 132, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 133, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 134, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 135, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 136, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 137, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 138, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 139, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 140, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 141, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 142, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 143, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 144, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 145, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 146, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 147, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 148, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 149, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 150, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 151, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 152, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 153, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 154, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 155, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 156, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 157, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 158, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 159, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 160, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 161, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 162, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 163, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 164, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 165, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 166, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 167, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 168, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 169, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 170, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 171, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 172, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 173, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 174, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 175, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 176, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 177, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 178, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 179, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 180, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 181, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 182, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 183, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 184, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 185, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 186, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 187, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 188, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 189, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 190, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 191, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 192, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 193, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 194, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 195, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 196, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 197, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 198, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 199, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 200, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 201, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 202, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 203, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 204, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 205, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 206, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 207, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 208, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 209, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 210, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 211, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 212, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 213, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 214, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 215, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 216, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 217, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 218, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 219, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 220, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 221, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 222, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 223, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 224, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 225, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 226, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 227, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 228, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 229, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 230, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 231, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 232, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 233, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 234, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 235, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 236, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 237, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 238, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 239, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 240, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 241, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 242, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 243, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 244, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 245, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 246, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 247, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 248, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 249, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 250, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 251, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 252, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 253, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 254, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 255, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 256, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 257, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 258, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 259, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 260, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 261, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 262, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 263, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 264, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 265, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 266, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 267, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 268, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 269, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 270, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 271, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 272, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 273, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 274, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 275, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 276, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 277, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 278, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 279, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 280, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 281, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 282, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 283, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 284, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 285, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 286, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 287, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 288, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 289, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 290, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 291, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 292, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 293, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 294, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 295, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 296, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 297, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 298, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}, {\"epoch\": 299, \"accuracy\": 50.0, \"optimizer\": \"Ftrl\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.FacetChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Dataset"
      ],
      "metadata": {
        "id": "0Ltp9l3GJTpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"fedesoriano/stroke-prediction-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOgZGRlKKLkm",
        "outputId": "e3e13ed4-6eff-4ae4-cbd3-a473d9bb9ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'stroke-prediction-dataset' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import (\n",
        "    SGD, RMSprop, Adam,\n",
        "    Adagrad, Adadelta, Adamax, Nadam, Ftrl\n",
        ")\n",
        "\n",
        "import kagglehub\n",
        "import os # Import the os module for path manipulation\n",
        "\n",
        "# ---------------------------------------\n",
        "# 1) Download Dataset\n",
        "# ---------------------------------------\n",
        "path = kagglehub.dataset_download(\"fedesoriano/stroke-prediction-dataset\")\n",
        "\n",
        "# Load CSV - Corrected: Join the directory path with the actual file name\n",
        "df = pd.read_csv(os.path.join(path, 'healthcare-dataset-stroke-data.csv'))\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Preprocess Data\n",
        "# ---------------------------------------\n",
        "\n",
        "# Drop id column\n",
        "df = df.drop(columns=[\"id\"])\n",
        "\n",
        "# Handle missing values (avg for bmi)\n",
        "df[\"bmi\"].fillna(df[\"bmi\"].mean(), inplace=True)\n",
        "\n",
        "# Convert categorical to numerical\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Split into features and labels\n",
        "X = df.drop(columns=[\"stroke\"]).values\n",
        "y = df[\"stroke\"].values\n",
        "\n",
        "# Normalize features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Train/Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 3) Custom Callback to stop at 100%\n",
        "# ---------------------------------------\n",
        "class StopAtAccuracy(Callback):\n",
        "    def __init__(self, target_accuracy=1.0):\n",
        "        super(StopAtAccuracy, self).__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        acc = logs.get(\"binary_accuracy\")\n",
        "        if acc >= self.target_accuracy:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# 4) Optimizers\n",
        "# ---------------------------------------\n",
        "optimizers = {\n",
        "    \"SGD\": SGD(learning_rate=0.01),\n",
        "    \"SGD_Momentum\": SGD(learning_rate=0.01, momentum=0.9),\n",
        "    \"SGD_Nesterov\": SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
        "    \"Adagrad\": Adagrad(learning_rate=0.01),\n",
        "    \"Adadelta\": Adadelta(learning_rate=1.0),\n",
        "    \"RMSprop\": RMSprop(learning_rate=0.001),\n",
        "    \"Adam\": Adam(learning_rate=0.001),\n",
        "    \"Adamax\": Adamax(learning_rate=0.001),\n",
        "    \"Nadam\": Nadam(learning_rate=0.001),\n",
        "    \"Ftrl\": Ftrl(learning_rate=0.01)\n",
        "}\n",
        "\n",
        "# ---------------------------------------\n",
        "# 5) Train & Compare Optimizers\n",
        "# ---------------------------------------\n",
        "results = []\n",
        "\n",
        "for name, opt in optimizers.items():\n",
        "    # Build model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=opt,\n",
        "        metrics=['binary_accuracy']\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=100,\n",
        "        verbose=0,\n",
        "        callbacks=[StopAtAccuracy(target_accuracy=1.0)]\n",
        "    )\n",
        "\n",
        "    # Save history\n",
        "    for epoch, acc in enumerate(history.history['binary_accuracy']):\n",
        "        results.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"accuracy\": acc * 100,\n",
        "            \"optimizer\": name\n",
        "        })\n",
        "\n",
        "# ---------------------------------------\n",
        "# 6) Plot Comparison Graph (clear)\n",
        "# ---------------------------------------\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "chart = alt.Chart(df_results).mark_line().encode(\n",
        "    x=alt.X('epoch', title='Epoch'),\n",
        "    y=alt.Y('accuracy', title='Accuracy (%)', scale=alt.Scale(domain=[0, 100])),\n",
        "    color='optimizer'\n",
        ").properties(\n",
        "    title='Optimizer Comparison on Stroke Prediction Dataset',\n",
        "    width=800,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "chart\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "y1TRNS2cJWuM",
        "outputId": "b89ecff4-4c5a-4d63-d036-a36518126c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'stroke-prediction-dataset' dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3651378528.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"bmi\"].fillna(df[\"bmi\"].mean(), inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-d786d61e5b6d45d597228e7fe41ab5c0.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-d786d61e5b6d45d597228e7fe41ab5c0.vega-embed details,\n",
              "  #altair-viz-d786d61e5b6d45d597228e7fe41ab5c0.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-d786d61e5b6d45d597228e7fe41ab5c0\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-d786d61e5b6d45d597228e7fe41ab5c0\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-d786d61e5b6d45d597228e7fe41ab5c0\");\n",
              "    }\n",
              "\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      let deps = [\"vega-embed\"];\n",
              "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-74c18371464ddb562247ae8c95c26814\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"optimizer\", \"type\": \"nominal\"}, \"x\": {\"field\": \"epoch\", \"title\": \"Epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Accuracy (%)\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Optimizer Comparison on Stroke Prediction Dataset\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-74c18371464ddb562247ae8c95c26814\": [{\"epoch\": 0, \"accuracy\": 89.0900194644928, \"optimizer\": \"SGD\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 43, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD\"}, {\"epoch\": 45, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 46, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 47, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 48, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 49, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 50, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 51, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 52, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 53, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 54, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 55, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 56, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 57, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 58, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 59, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 60, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 61, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 62, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 63, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 64, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 65, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 66, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 67, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 68, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 69, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 70, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 71, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 72, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 73, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 74, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 75, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 76, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 77, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 78, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 79, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 80, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 81, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 82, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 83, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 84, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 85, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 86, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 87, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 88, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 89, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 90, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 91, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 92, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 93, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 94, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 95, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 96, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 97, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 98, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 99, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD\"}, {\"epoch\": 0, \"accuracy\": 94.54501271247864, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 43, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 45, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 46, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 47, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 48, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 49, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 50, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 51, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 52, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 53, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 54, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 55, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 56, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 57, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 58, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 59, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 60, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 61, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 62, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 63, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 64, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 65, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 66, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 67, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 68, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 69, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 70, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 71, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 72, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 73, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 74, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 75, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 76, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 77, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 78, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 79, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 80, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 81, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 82, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 83, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 84, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 85, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 86, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 87, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 88, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 89, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 90, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 91, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 92, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 93, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 94, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 95, \"accuracy\": 95.59686779975891, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 96, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 97, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 98, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 99, \"accuracy\": 95.59686779975891, \"optimizer\": \"SGD_Momentum\"}, {\"epoch\": 0, \"accuracy\": 92.78375506401062, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 1, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 12, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 13, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 14, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 28, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 29, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 30, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 31, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 32, \"accuracy\": 95.40117383003235, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 34, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 35, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 36, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 37, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 38, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 39, \"accuracy\": 95.45009732246399, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 40, \"accuracy\": 95.47455906867981, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 41, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 42, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 43, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 44, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 45, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 46, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 47, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 48, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 49, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 50, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 51, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 52, \"accuracy\": 95.49902081489563, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 53, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 54, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 55, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 56, \"accuracy\": 95.54794430732727, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 57, \"accuracy\": 95.57240605354309, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 58, \"accuracy\": 95.52348256111145, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 59, \"accuracy\": 95.62132954597473, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 60, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 61, \"accuracy\": 95.62132954597473, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 62, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 63, \"accuracy\": 95.59686779975891, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 64, \"accuracy\": 95.62132954597473, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 65, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 66, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 67, \"accuracy\": 95.62132954597473, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 68, \"accuracy\": 95.62132954597473, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 69, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 70, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 71, \"accuracy\": 95.67025303840637, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 72, \"accuracy\": 95.67025303840637, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 73, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 74, \"accuracy\": 95.67025303840637, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 75, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 76, \"accuracy\": 95.74363827705383, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 77, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 78, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 79, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 80, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 81, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 82, \"accuracy\": 95.74363827705383, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 83, \"accuracy\": 95.74363827705383, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 84, \"accuracy\": 95.76810002326965, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 85, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 86, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 87, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 88, \"accuracy\": 95.74363827705383, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 89, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 90, \"accuracy\": 95.67025303840637, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 91, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 92, \"accuracy\": 95.67025303840637, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 93, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 94, \"accuracy\": 95.64579129219055, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 95, \"accuracy\": 95.69471478462219, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 96, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 97, \"accuracy\": 95.74363827705383, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 98, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 99, \"accuracy\": 95.71917653083801, \"optimizer\": \"SGD_Nesterov\"}, {\"epoch\": 0, \"accuracy\": 86.30136847496033, \"optimizer\": \"Adagrad\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 43, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 45, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 46, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 47, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 48, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 49, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 50, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 51, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 52, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 53, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 54, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 55, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 56, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 57, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 58, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 59, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 60, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 61, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 62, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 63, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 64, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 65, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 66, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 67, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 68, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 69, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 70, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 71, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 72, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 73, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 74, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 75, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 76, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 77, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 78, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 79, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 80, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 81, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 82, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 83, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 84, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 85, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 86, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 87, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 88, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 89, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 90, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 91, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 92, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 93, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 94, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 95, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 96, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 97, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 98, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 99, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adagrad\"}, {\"epoch\": 0, \"accuracy\": 95.18101811408997, \"optimizer\": \"Adadelta\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 43, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 45, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adadelta\"}, {\"epoch\": 46, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adadelta\"}, {\"epoch\": 47, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adadelta\"}, {\"epoch\": 48, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adadelta\"}, {\"epoch\": 49, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adadelta\"}, {\"epoch\": 50, \"accuracy\": 95.47455906867981, \"optimizer\": \"Adadelta\"}, {\"epoch\": 51, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adadelta\"}, {\"epoch\": 52, \"accuracy\": 95.47455906867981, \"optimizer\": \"Adadelta\"}, {\"epoch\": 53, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 54, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 55, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 56, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 57, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 58, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 59, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 60, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 61, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 62, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 63, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 64, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 65, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 66, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 67, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 68, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 69, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 70, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 71, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 72, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adadelta\"}, {\"epoch\": 73, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 74, \"accuracy\": 95.52348256111145, \"optimizer\": \"Adadelta\"}, {\"epoch\": 75, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 76, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adadelta\"}, {\"epoch\": 77, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 78, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adadelta\"}, {\"epoch\": 79, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 80, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 81, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adadelta\"}, {\"epoch\": 82, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adadelta\"}, {\"epoch\": 83, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 84, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adadelta\"}, {\"epoch\": 85, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adadelta\"}, {\"epoch\": 86, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adadelta\"}, {\"epoch\": 87, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adadelta\"}, {\"epoch\": 88, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adadelta\"}, {\"epoch\": 89, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adadelta\"}, {\"epoch\": 90, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adadelta\"}, {\"epoch\": 91, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 92, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 93, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adadelta\"}, {\"epoch\": 94, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 95, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 96, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 97, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 98, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 99, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adadelta\"}, {\"epoch\": 0, \"accuracy\": 82.77886509895325, \"optimizer\": \"RMSprop\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 43, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 45, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 46, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 47, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 48, \"accuracy\": 95.40117383003235, \"optimizer\": \"RMSprop\"}, {\"epoch\": 49, \"accuracy\": 95.40117383003235, \"optimizer\": \"RMSprop\"}, {\"epoch\": 50, \"accuracy\": 95.40117383003235, \"optimizer\": \"RMSprop\"}, {\"epoch\": 51, \"accuracy\": 95.37671208381653, \"optimizer\": \"RMSprop\"}, {\"epoch\": 52, \"accuracy\": 95.37671208381653, \"optimizer\": \"RMSprop\"}, {\"epoch\": 53, \"accuracy\": 95.37671208381653, \"optimizer\": \"RMSprop\"}, {\"epoch\": 54, \"accuracy\": 95.40117383003235, \"optimizer\": \"RMSprop\"}, {\"epoch\": 55, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 56, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 57, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 58, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 59, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 60, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 61, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 62, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 63, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 64, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 65, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 66, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 67, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 68, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 69, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 70, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 71, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 72, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 73, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 74, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 75, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 76, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 77, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 78, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 79, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 80, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 81, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 82, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 83, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 84, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 85, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 86, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 87, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 88, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 89, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 90, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 91, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 92, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 93, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 94, \"accuracy\": 95.47455906867981, \"optimizer\": \"RMSprop\"}, {\"epoch\": 95, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 96, \"accuracy\": 95.42563557624817, \"optimizer\": \"RMSprop\"}, {\"epoch\": 97, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 98, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 99, \"accuracy\": 95.45009732246399, \"optimizer\": \"RMSprop\"}, {\"epoch\": 0, \"accuracy\": 95.00978589057922, \"optimizer\": \"Adam\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 15, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 19, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 35, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 36, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 37, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 38, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 39, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 40, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adam\"}, {\"epoch\": 43, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 44, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 45, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 46, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 47, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 48, \"accuracy\": 95.45009732246399, \"optimizer\": \"Adam\"}, {\"epoch\": 49, \"accuracy\": 95.47455906867981, \"optimizer\": \"Adam\"}, {\"epoch\": 50, \"accuracy\": 95.47455906867981, \"optimizer\": \"Adam\"}, {\"epoch\": 51, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 52, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 53, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 54, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 55, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 56, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 57, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 58, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 59, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 60, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 61, \"accuracy\": 95.49902081489563, \"optimizer\": \"Adam\"}, {\"epoch\": 62, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adam\"}, {\"epoch\": 63, \"accuracy\": 95.57240605354309, \"optimizer\": \"Adam\"}, {\"epoch\": 64, \"accuracy\": 95.54794430732727, \"optimizer\": \"Adam\"}, {\"epoch\": 65, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adam\"}, {\"epoch\": 66, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adam\"}, {\"epoch\": 67, \"accuracy\": 95.59686779975891, \"optimizer\": \"Adam\"}, {\"epoch\": 68, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adam\"}, {\"epoch\": 69, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 70, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 71, \"accuracy\": 95.69471478462219, \"optimizer\": \"Adam\"}, {\"epoch\": 72, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 73, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 74, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 75, \"accuracy\": 95.74363827705383, \"optimizer\": \"Adam\"}, {\"epoch\": 76, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 77, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 78, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 79, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 80, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 81, \"accuracy\": 95.69471478462219, \"optimizer\": \"Adam\"}, {\"epoch\": 82, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 83, \"accuracy\": 95.69471478462219, \"optimizer\": \"Adam\"}, {\"epoch\": 84, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 85, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 86, \"accuracy\": 95.71917653083801, \"optimizer\": \"Adam\"}, {\"epoch\": 87, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 88, \"accuracy\": 95.69471478462219, \"optimizer\": \"Adam\"}, {\"epoch\": 89, \"accuracy\": 95.64579129219055, \"optimizer\": \"Adam\"}, {\"epoch\": 90, \"accuracy\": 95.69471478462219, \"optimizer\": \"Adam\"}, {\"epoch\": 91, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 92, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 93, \"accuracy\": 95.69471478462219, \"optimizer\": \"Adam\"}, {\"epoch\": 94, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 95, \"accuracy\": 95.67025303840637, \"optimizer\": \"Adam\"}, {\"epoch\": 96, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adam\"}, {\"epoch\": 97, \"accuracy\": 95.62132954597473, \"optimizer\": \"Adam\"}, {\"epoch\": 98, \"accuracy\": 95.64579129219055, \"optimizer\": \"Adam\"}, {\"epoch\": 99, \"accuracy\": 95.64579129219055, \"optimizer\": \"Adam\"}, {\"epoch\": 0, \"accuracy\": 88.79647850990295, \"optimizer\": \"Adamax\"}, {\"epoch\": 1, \"accuracy\": 94.88747715950012, \"optimizer\": \"Adamax\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 43, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 45, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 46, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 47, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 48, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 49, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 50, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 51, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 52, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 53, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 54, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 55, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 56, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 57, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 58, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 59, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 60, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 61, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 62, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 63, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 64, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 65, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 66, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 67, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 68, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 69, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 70, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 71, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 72, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 73, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 74, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 75, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 76, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 77, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 78, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 79, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 80, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 81, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 82, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 83, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 84, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 85, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 86, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 87, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 88, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 89, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 90, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 91, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 92, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 93, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 94, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 95, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 96, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 97, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 98, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 99, \"accuracy\": 95.42563557624817, \"optimizer\": \"Adamax\"}, {\"epoch\": 0, \"accuracy\": 91.97651743888855, \"optimizer\": \"Nadam\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"Nadam\"}, {\"epoch\": 14, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 15, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 16, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 17, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 18, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 19, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 20, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 21, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 22, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 23, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 24, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 25, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 26, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 27, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 28, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 29, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 30, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 31, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 32, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 33, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 34, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 35, \"accuracy\": 95.45009732246399, \"optimizer\": \"Nadam\"}, {\"epoch\": 36, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 37, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 38, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 39, \"accuracy\": 95.47455906867981, \"optimizer\": \"Nadam\"}, {\"epoch\": 40, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 41, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 42, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 43, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 44, \"accuracy\": 95.49902081489563, \"optimizer\": \"Nadam\"}, {\"epoch\": 45, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 46, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 47, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 48, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 49, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 50, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 51, \"accuracy\": 95.52348256111145, \"optimizer\": \"Nadam\"}, {\"epoch\": 52, \"accuracy\": 95.54794430732727, \"optimizer\": \"Nadam\"}, {\"epoch\": 53, \"accuracy\": 95.54794430732727, \"optimizer\": \"Nadam\"}, {\"epoch\": 54, \"accuracy\": 95.54794430732727, \"optimizer\": \"Nadam\"}, {\"epoch\": 55, \"accuracy\": 95.54794430732727, \"optimizer\": \"Nadam\"}, {\"epoch\": 56, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 57, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 58, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 59, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 60, \"accuracy\": 95.62132954597473, \"optimizer\": \"Nadam\"}, {\"epoch\": 61, \"accuracy\": 95.64579129219055, \"optimizer\": \"Nadam\"}, {\"epoch\": 62, \"accuracy\": 95.62132954597473, \"optimizer\": \"Nadam\"}, {\"epoch\": 63, \"accuracy\": 95.62132954597473, \"optimizer\": \"Nadam\"}, {\"epoch\": 64, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 65, \"accuracy\": 95.64579129219055, \"optimizer\": \"Nadam\"}, {\"epoch\": 66, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 67, \"accuracy\": 95.57240605354309, \"optimizer\": \"Nadam\"}, {\"epoch\": 68, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 69, \"accuracy\": 95.54794430732727, \"optimizer\": \"Nadam\"}, {\"epoch\": 70, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 71, \"accuracy\": 95.57240605354309, \"optimizer\": \"Nadam\"}, {\"epoch\": 72, \"accuracy\": 95.57240605354309, \"optimizer\": \"Nadam\"}, {\"epoch\": 73, \"accuracy\": 95.57240605354309, \"optimizer\": \"Nadam\"}, {\"epoch\": 74, \"accuracy\": 95.57240605354309, \"optimizer\": \"Nadam\"}, {\"epoch\": 75, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 76, \"accuracy\": 95.59686779975891, \"optimizer\": \"Nadam\"}, {\"epoch\": 77, \"accuracy\": 95.62132954597473, \"optimizer\": \"Nadam\"}, {\"epoch\": 78, \"accuracy\": 95.62132954597473, \"optimizer\": \"Nadam\"}, {\"epoch\": 79, \"accuracy\": 95.62132954597473, \"optimizer\": \"Nadam\"}, {\"epoch\": 80, \"accuracy\": 95.67025303840637, \"optimizer\": \"Nadam\"}, {\"epoch\": 81, \"accuracy\": 95.67025303840637, \"optimizer\": \"Nadam\"}, {\"epoch\": 82, \"accuracy\": 95.64579129219055, \"optimizer\": \"Nadam\"}, {\"epoch\": 83, \"accuracy\": 95.67025303840637, \"optimizer\": \"Nadam\"}, {\"epoch\": 84, \"accuracy\": 95.67025303840637, \"optimizer\": \"Nadam\"}, {\"epoch\": 85, \"accuracy\": 95.67025303840637, \"optimizer\": \"Nadam\"}, {\"epoch\": 86, \"accuracy\": 95.64579129219055, \"optimizer\": \"Nadam\"}, {\"epoch\": 87, \"accuracy\": 95.74363827705383, \"optimizer\": \"Nadam\"}, {\"epoch\": 88, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 89, \"accuracy\": 95.69471478462219, \"optimizer\": \"Nadam\"}, {\"epoch\": 90, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 91, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 92, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 93, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 94, \"accuracy\": 95.64579129219055, \"optimizer\": \"Nadam\"}, {\"epoch\": 95, \"accuracy\": 95.64579129219055, \"optimizer\": \"Nadam\"}, {\"epoch\": 96, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 97, \"accuracy\": 95.69471478462219, \"optimizer\": \"Nadam\"}, {\"epoch\": 98, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 99, \"accuracy\": 95.71917653083801, \"optimizer\": \"Nadam\"}, {\"epoch\": 0, \"accuracy\": 95.32778859138489, \"optimizer\": \"Ftrl\"}, {\"epoch\": 1, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 2, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 3, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 4, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 5, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 6, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 7, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 8, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 9, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 10, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 11, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 12, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 13, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 14, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 15, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 16, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 17, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 18, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 19, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 20, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 21, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 22, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 23, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 24, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 25, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 26, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 27, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 28, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 29, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 30, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 31, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 32, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 33, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 34, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 35, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 36, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 37, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 38, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 39, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 40, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 41, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 42, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 43, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 44, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 45, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 46, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 47, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 48, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 49, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 50, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 51, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 52, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 53, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 54, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 55, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 56, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 57, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 58, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 59, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 60, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 61, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 62, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 63, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 64, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 65, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 66, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 67, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 68, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 69, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 70, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 71, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 72, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 73, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 74, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 75, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 76, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 77, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 78, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 79, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 80, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 81, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 82, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 83, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 84, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 85, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 86, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 87, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 88, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 89, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 90, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 91, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 92, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 93, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 94, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 95, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 96, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 97, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 98, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}, {\"epoch\": 99, \"accuracy\": 95.42563557624817, \"optimizer\": \"Ftrl\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "NxurrMWDIfQa"
      }
    }
  ]
}